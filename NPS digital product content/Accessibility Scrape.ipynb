{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7643e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "043e842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daniel.Lang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns \n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from VE_scraper_functions import *\n",
    "from chromedriver_py import binary_path # this will get you the path variable\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbb679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"park_scrape_content_dataset.xlsx\"\n",
    "park_scrape_dataset2 = pd.read_excel(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401c8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "             \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \n",
    "             \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "             \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\",\n",
    "             \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \n",
    "             \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "             \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \n",
    "             \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\n",
    "             \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \n",
    "             \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \n",
    "             \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \n",
    "             \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \n",
    "             \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \n",
    "             \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\",\n",
    "            \"href\",\"=\",\"/\",\">\",\"<\",\"]\",\"[\",\"span\",\"'\\n'\",'class',\"jstcache\",\n",
    "            \"onclick\",\"null\",\"jscontent\",\" <br/>\",\"</span>\",\",\",\";\",\"(\",\")\",\"{\",\"}\",\":\",\"''\",\n",
    "            \"&\",\"'\",\"var\",\"+=\",\".\",\"#\",\"-\",\"=\",\"+\",\"``\",\"0\",\"â€™\",\"data.operatingHours\",\"outputVarOperatingHours\",\n",
    "            \".exceptions\",\"--\",\"1\",\"-1\",\"?\",\"class=\",\"==\",\"div\",\"/div\",\"$\",\"li\",\"e\",\"!\",\"k\",\"/span\",\"jQuery\",\n",
    "            \"tabindex\",'j','l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddda920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "Current Park:  BAND :  25  checks done;  399  remaining; Processing Time:  9.0\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n",
      "0    0\n",
      "Name: Accessibility_information, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     tic\u001b[38;5;241m=\u001b[39mtoc\n\u001b[0;32m     21\u001b[0m this_park \u001b[38;5;241m=\u001b[39m park_scrape_dataset2[(park_scrape_dataset2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpark\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mx)] \u001b[38;5;66;03m#filter our webscraping dataset for our park's website code\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m park_final \u001b[38;5;241m=\u001b[39m \u001b[43mTraveler_Info_Finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_park\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#run function\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(park_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessibility_information\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m park_sheet \u001b[38;5;241m=\u001b[39m park_sheet\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpark\u001b[39m\u001b[38;5;124m'\u001b[39m: park_final\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpark\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     25\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite page count\u001b[39m\u001b[38;5;124m'\u001b[39m: park_final\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite page\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     26\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDirections_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m: park_final\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDirections_count\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m                    },\n\u001b[0;32m     40\u001b[0m                   ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\NPS-Emerging-Mobility\\NPS digital product content\\VE_scraper_functions.py:266\u001b[0m, in \u001b[0;36mTraveler_Info_Finder\u001b[1;34m(park)\u001b[0m\n\u001b[0;32m    264\u001b[0m park[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCongestion_information\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mCongestion_count\n\u001b[0;32m    265\u001b[0m park[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBike_Pedestrian_Information\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mBike_Ped_count\n\u001b[1;32m--> 266\u001b[0m park[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTravel_dist_information\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mTravel_dist_count\n\u001b[0;32m    267\u001b[0m park[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTravel_other_dist_information\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mTravel_dist_other_count\n\u001b[0;32m    268\u001b[0m park[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessibility_intro_information\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mAccessibility_count\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\frame.py:3845\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3842\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   3843\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 3845\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 3810\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_setitem_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\generic.py:4018\u001b[0m, in \u001b[0;36mNDFrame._check_setitem_copy\u001b[1;34m(self, t, force)\u001b[0m\n\u001b[0;32m   4016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m com\u001b[38;5;241m.\u001b[39mSettingWithCopyError(t)\n\u001b[0;32m   4017\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 4018\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(t, com\u001b[38;5;241m.\u001b[39mSettingWithCopyWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[43mfind_stack_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\util\\_exceptions.py:32\u001b[0m, in \u001b[0;36mfind_stack_level\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_stack_level\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Find the first place in the stack that is not inside pandas\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    (tests notwithstanding).\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     pkg_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(pd\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\inspect.py:1678\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(context\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1677\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetouterframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\inspect.py:1655\u001b[0m, in \u001b[0;36mgetouterframes\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1653\u001b[0m framelist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame:\n\u001b[1;32m-> 1655\u001b[0m     frameinfo \u001b[38;5;241m=\u001b[39m (frame,) \u001b[38;5;241m+\u001b[39m \u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1656\u001b[0m     framelist\u001b[38;5;241m.\u001b[39mappend(FrameInfo(\u001b[38;5;241m*\u001b[39mframeinfo))\n\u001b[0;32m   1657\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\inspect.py:1625\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isframe(frame):\n\u001b[0;32m   1623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a frame or traceback object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(frame))\n\u001b[1;32m-> 1625\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m getfile(frame)\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1627\u001b[0m     start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\inspect.py:826\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    824\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Model to calculate VE fields ##\n",
    "\n",
    "#create new sheet so with our variables for each park\n",
    "park_sheet = pd.DataFrame(columns = ['park', 'Driving_Directions','Public_transportation_information',\n",
    "                                     'Bike_Pedestrian_Information','Congestion_information','Accessibility',\n",
    "                                           'Alternative_Fueling_Stations', 'website page count'])\n",
    "z=0\n",
    "tic = time.process_time() #function to let us track processing time\n",
    "\n",
    "\n",
    "for x in park_scrape_dataset2['park'].unique():\n",
    "    z+=1\n",
    "    if z % 25 == 0: \n",
    "        #function to let us track processing time\n",
    "        z5 = 424-z\n",
    "        toc = time.process_time()\n",
    "        time_diff = toc-tic\n",
    "        print(\"Current Park: \", x, \": \", z, \" checks done; \", z5, \" remaining; Processing Time: \",time_diff)\n",
    "        tic=toc\n",
    "        \n",
    "    this_park = park_scrape_dataset2[(park_scrape_dataset2['park']==x)] #filter our webscraping dataset for our park's website code\n",
    "    park_final = Traveler_Info_Finder(this_park) #run function\n",
    "    print(park_final['Accessibility_information'])\n",
    "    park_sheet = park_sheet.append({'park': park_final._get_value(0,'park'),\n",
    "                        'website page count': park_final._get_value(0,'website page'),\n",
    "                        'Directions_word_count': park_final._get_value(0,'Directions_count'),\n",
    "                        'Directions_page_count': park_final._get_value(0,'Directions_page_count'),\n",
    "                       'Driving_Directions': park_final._get_value(0,'MajorDirections_count'),\n",
    "                       'Public_transportation_information': park_final._get_value(0,'Public_transportation_information'),\n",
    "                       'Alternative_Fueling_Stations': park_final._get_value(0,'Alternative_Fueling_Stations'), \n",
    "                       'Bike_Pedestrian_Information': park_final._get_value(0,'Bike_Pedestrian_Information'),\n",
    "                       'Congestion_information': park_final._get_value(0,'Congestion_information'),\n",
    "                        'Travel_Distance_Information': park_final._get_value(0,'Travel_dist_information'),\n",
    "                        'Travel_other_dist_information': park_final._get_value(0,'Travel_other_dist_information'),\n",
    "                        'Accessibility': park_final._get_value(0,'Accessibility_information'),\n",
    "                        'Parking_raw_information': park_final._get_value(0,'Parking_information'),\n",
    "                        'Parking_experience_information': park_final._get_value(0,'Parking_experience_information'),\n",
    "                        'Parking_max_on_one_site': park_final._get_value(0,'Parking_max_on_one_site')\n",
    "                       },\n",
    "                      ignore_index=True)\n",
    "    park_sheet.loc[park_sheet.Driving_Directions > 0, 'Driving_Directions'] = 1\n",
    "    park_sheet.loc[park_sheet.Alternative_Fueling_Stations > 0, 'Alternative_Fueling_Stations'] = 1\n",
    "    park_sheet.loc[park_sheet.Public_transportation_information > 0, 'Public_transportation_information'] = 1\n",
    "    park_sheet.loc[park_sheet.Bike_Pedestrian_Information > 0, 'Bike_Pedestrian_Information'] = 1\n",
    "    park_sheet.loc[park_sheet.Congestion_information > 0, 'Congestion_information'] = 1\n",
    "    park_sheet.loc[park_sheet.Accessibility > 0, 'Accessibility'] = 1\n",
    " #   park_sheet.loc[park_sheet.Parking_information > 0, 'Parking_information'] = 1\n",
    "    park_sheet['Travel_Distance_Final']=np.where(\n",
    "        np.logical_or(park_sheet['Travel_Distance_Information']>9, \n",
    "                     park_sheet['Travel_other_dist_information']>0),1,0)\n",
    "    park_sheet['Parking_Experience_information']=np.where((\n",
    "        park_sheet['Parking_raw_information']/park_sheet['website page count'])>0.25,1,0)\n",
    "    park_sheet['Transportation_experience_information']=np.where((\n",
    "        park_sheet['Directions_page_count']/park_sheet['website page count'])>0.65,1,0)\n",
    "    park_sheet['Parking_information']=np.where(np.logical_or(\n",
    "        park_sheet['Parking_Experience_information']==1,\n",
    "        park_sheet['Parking_max_on_one_site']>2),1,0)\n",
    "\n",
    "\n",
    "park_sheet= park_sheet.drop(columns=['website page count', 'Directions_word_count',\n",
    "                        'Directions_page_count','Parking_raw_information','Parking_experience_information',\n",
    "                        'Parking_max_on_one_site','Travel_Distance_Information','Travel_other_dist_information'])\n",
    "    \n",
    "#create csv\n",
    "park_sheet.to_csv(\"final_park.csv\") #save final csv\n",
    "os.system(\"start EXCEL.EXE final_park.csv\") #open csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d329162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park</th>\n",
       "      <th>MajorDirections_count</th>\n",
       "      <th>Directions_count</th>\n",
       "      <th>Directions_page_count</th>\n",
       "      <th>Public_transportation_information</th>\n",
       "      <th>Alternative_Fueling_Stations</th>\n",
       "      <th>Bike_Pedestrian_Information</th>\n",
       "      <th>Congestion_information</th>\n",
       "      <th>Travel_dist_information</th>\n",
       "      <th>Travel_other_dist_information</th>\n",
       "      <th>Accessibility_information</th>\n",
       "      <th>Parking_information</th>\n",
       "      <th>Parking_experience_information</th>\n",
       "      <th>Parking_max_on_one_site</th>\n",
       "      <th>website page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZION</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   park  MajorDirections_count  Directions_count  Directions_page_count  Public_transportation_information  Alternative_Fueling_Stations  Bike_Pedestrian_Information  Congestion_information  Travel_dist_information  Travel_other_dist_information  Accessibility_information  Parking_information  Parking_experience_information  Parking_max_on_one_site  website page\n",
       "0  ZION                     22                 0                     22                                 16                             0                            3                       1                       10                              0                          0                   17                               0                        0            22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "park_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "609d6d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "park_sheet.to_csv(\"final_park.csv\") #save final csv\n",
    "os.system(\"start EXCEL.EXE final_park.csv\") #open csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "309cfe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_park = park_scrape_dataset2[(park_scrape_dataset2['park']=='ZION')]\n",
    "\n",
    "Accessibility_Words = [\n",
    "        \"wheelchair\", \"accessibility\", \"disability\", \"impaired\", \"disabilities\", \"handicap\",\n",
    "        \"accessible\",\"Wheelchair\"\n",
    "    ]\n",
    "\n",
    "Directions_Words = [\"Entrance\",\"Center\",\"street\",\"Visitor\"\n",
    "                    \"Street\",\"parking\",\"directions\",\"Route\",\"Road\",\n",
    "                    \"Interstate\",\"Exit\",\n",
    "                    \"mile\",\"km\",\"ferry\",\"access\", \"Street\",\"Blvd\", \"Hwy\"\n",
    "                   ]\n",
    "\n",
    "Parking_Words = [\n",
    "    \"parking\", \"Parking\", \"pullout\"\n",
    "]\n",
    "Direction_count = []\n",
    "Congestion_count = []\n",
    "Travel_dist_count = []\n",
    "Travel_dist_other_count=[]\n",
    "Accessibility_count=[]\n",
    "Parking_count=[]\n",
    "Parking_plan_count=[]\n",
    "\n",
    "Accessibility_information_count = []\n",
    "\n",
    "for x in this_park['content']:\n",
    "    z=0\n",
    "    z2=0\n",
    "    z3=0\n",
    "\n",
    "\n",
    "    major = 0\n",
    "    congestion = 0\n",
    "    pubtrans=0\n",
    "    bikeped=0\n",
    "    try:\n",
    "        tokenized_word=word_tokenize(x)\n",
    "        filtered_sent=[]\n",
    "        stemmed_words=[]\n",
    "        direction_words_temp = []\n",
    "        for w in tokenized_word:\n",
    "            if w not in stopwords:\n",
    "                filtered_sent.append(w)\n",
    "        for w in filtered_sent:\n",
    "            if w in Directions_Words:\n",
    "                z += 1\n",
    "            if w in Parking_Words:\n",
    "                z2 +=1\n",
    "            if w in Accessibility_Words:\n",
    "                z3 += 1\n",
    "        Direction_count.append(z)\n",
    "        Parking_plan_count.append(z2)\n",
    "        Accessibility_count.append(z3)\n",
    "        Accessibility_info = np.where(np.logical_and(z2>2,z3>2),1,0)\n",
    "        Accessibility_information_count.append(Accessibility_info)\n",
    "    except:\n",
    "        Direction_count.append(0)\n",
    "        Parking_plan_count.append(0)\n",
    "        Accessibility_count.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "931deba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and(z2>2,z3>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39b964f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(1),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0),\n",
       " array(0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accessibility_information_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed7dd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Accessibility_information_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2874be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e27a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m----> 2\u001b[0m         np\u001b[38;5;241m.\u001b[39mlogical_or(\u001b[43mAccessibility_count\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m                      Parking_plan_count\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m),\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "np.where(\n",
    "        np.logical_or(Accessibility_count>2,\n",
    "                     Parking_plan_count>2),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accessibility_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
