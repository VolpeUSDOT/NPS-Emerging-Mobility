{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns \n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from VE_scraper_functions import *\n",
    "from chromedriver_py import binary_path # this will get you the path variable\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "path = \"park_scrape_content_dataset.xlsx\"\n",
    "park_scrape_dataset2 = pd.read_excel(path)\n",
    "park_scrape_dataset2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert all text to lowercase to avoid case sensitivity issues\n",
    "park_scrape_dataset2['content'] = park_scrape_dataset2['content'].str.lower()\n",
    "## remove harpers ferry\n",
    "park_scrape_dataset2['content'] = park_scrape_dataset2['content'].str.replace('harpers ferry', '')\n",
    "park_scrape_dataset2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_words =  [\n",
    "       \" bus \", \"shuttle\", \"transit\", \"public transportation\", \"ferry\", \"ferry service\", \"subway\", \"train\", \"metro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b496e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pt_words(text):\n",
    "    word_counts = {word: text.lower().count(word) for word in pt_words}\n",
    "    return word_counts\n",
    "word_counts_df = park_scrape_dataset2['content'].apply(count_pt_words).apply(pd.Series)\n",
    "word_counts_df['total'] = word_counts_df.sum(axis=1)\n",
    "word_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc64f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_scrape_dataset2 = pd.concat([park_scrape_dataset2, word_counts_df], axis=1)\n",
    "park_scrape_dataset2 = park_scrape_dataset2.drop(\"content\", axis=\"columns\")\n",
    "park_scrape_dataset2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_scrape_dataset2.to_csv(\"pttest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc85f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"clusterlookup.csv\"\n",
    "clusters = pd.read_csv(path)\n",
    "clusters.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053336bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_word_counts = park_scrape_dataset2.groupby('park')[pt_words].sum()\n",
    "park_word_counts['total'] = park_word_counts.sum(axis=1)\n",
    "park_word_counts.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersubset = clusters[['Park Alpha', \"FinalCluster\", \"Label\"]]\n",
    "clustersubset.rename(columns={'Park Alpha':\"park\"}, inplace = True)\n",
    "clusterparks = pd.merge(park_word_counts, clustersubset, on=\"park\", how=\"left\")\n",
    "clusterparks['ferrynet'] = clusterparks['ferry'] - clusterparks['ferry service']\n",
    "clusterparks.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterparks.to_csv(\"ptbypark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93846064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_parks_counts = clusterparks.groupby('Label').size().reset_index(name='Total_Parks')\n",
    "total_parks_counts['Total_Parks'] = total_parks_counts['Total_Parks'].astype(int) \n",
    "filtered_df = clusterparks[clusterparks['total'] > 1]\n",
    "ev_parks_counts = filtered_df.groupby('Label').size().reset_index(name='pt_Parks')\n",
    "label_counts = pd.merge(total_parks_counts, ev_parks_counts, on='Label', how='left')\n",
    "label_counts['pt_Parks'].fillna(0, inplace=True)\n",
    "label_counts['Percent_pt'] = round((label_counts['pt_Parks'] / label_counts['Total_Parks']) * 100, 1)\n",
    "label_counts['pt_Parks'] = label_counts['pt_Parks'].astype(int)\n",
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_row = label_counts.sum(numeric_only=True)\n",
    "total_row['Label'] = 'Total'\n",
    "total_counts = label_counts.append(total_row, ignore_index=True)\n",
    "total_counts['pt_Parks'] = total_counts['pt_Parks'].astype(int)\n",
    "total_counts['Total_Parks'] = total_counts['Total_Parks'].astype(int)\n",
    "total_counts.loc[total_counts['Label'] == 'Total', 'Percent_pt'] = round((total_counts.loc[total_counts['Label'] == 'Total', 'pt_Parks'] / total_counts.loc[total_counts['Label'] == 'Total', 'Total_Parks']) * 100, 1)\n",
    "total_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts.to_csv(\"ptbycluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6)) \n",
    "plt.bar(label_counts['Label'], label_counts['Percent_pt'], color='#C56C39')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Percentage of Public Transportation Parks')\n",
    "plt.title('Percentage of Parks with Public Transportation Information in Each Cluster')\n",
    "plt.xticks(rotation=45, ha='right') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea37a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6)) \n",
    "bars = plt.bar(label_counts['Label'], label_counts['Percent_pt'], color='#C56C39')\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    pt_parks = label_counts['pt_Parks'].iloc[i]\n",
    "    total_parks = label_counts['Total_Parks'].iloc[i]\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.25,\n",
    "             f\"{pt_parks}/{total_parks}\",\n",
    "             ha='center', va='bottom')\n",
    "    \n",
    "##avg_percent_ev = label_counts['Percent_EV'].mean()\n",
    "##plt.axhline(y=avg_percent_ev, color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Percentage of Public Transportation Parks')\n",
    "plt.title('Percentage of Parks with Public Transportation Information in Each Cluster')\n",
    "plt.xticks(rotation=45, ha='right') \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ptGraph.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {word: park_word_counts[word].mean() for word in pt_words}\n",
    "plt.figure(figsize=(10, 6))\n",
    "park_word_counts.boxplot(column=pt_words)\n",
    "plt.title('Box and Whisker Plot of Transportation Words')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(averages.keys(), averages.values(), color='skyblue')\n",
    "plt.title('Average Counts of Transportation Words')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Average Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299758a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df494c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
