{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f79ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunk 1: Import libraries\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165dd571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Park Code: GRCA\n",
      "Do you want the tool to be based on 1. the current date or 2. a custom date range: 2\n",
      "Tool mode entered: 2\n",
      "Define custom start date as YYYYMMDD: 20240801\n",
      "Define custom end date as YYYYMMDD: 20240915\n",
      "Creating GTFS for dates between 20240801 and 20240915\n",
      "Extracted GRCA.zip to the folder GRCA_unzipped\n"
     ]
    }
   ],
   "source": [
    "#Chunk 2: Initialize\n",
    "# Enter Park Code\n",
    "park_name = input(\"Enter the Park Code: \").strip()\n",
    "\n",
    "# Set which calendar to use\n",
    "tool_mode = input(\"Do you want the tool to be based on 1. the current date or 2. a custom date range: \").strip()\n",
    "\n",
    "# Debugging: Check the value of tool_mode\n",
    "print(f\"Tool mode entered: {tool_mode}\")\n",
    "\n",
    "if tool_mode == '1':  # Compare as string\n",
    "    current_date_mode = input(\"Show 1. all active schedules or 2. all active and future schedules: \").strip()\n",
    "    if current_date_mode == '1' or current_date_mode == '2':\n",
    "        print(f\"Current date mode entered: {current_date_mode}\")\n",
    "    else:\n",
    "        print(\"Invalid option selected for tool mode.\")\n",
    "        sys.exit()\n",
    "elif tool_mode == '2':  # Compare as string\n",
    "    custom_start = input(\"Define custom start date as YYYYMMDD: \").strip()\n",
    "    custom_end = input(\"Define custom end date as YYYYMMDD: \").strip()\n",
    "    print(f\"Creating GTFS for dates between {custom_start} and {custom_end}\")\n",
    "    custom_start = pd.to_datetime(custom_start, format='%Y%m%d')\n",
    "    custom_end = pd.to_datetime(custom_end, format='%Y%m%d')\n",
    "else:\n",
    "    print(\"Invalid option selected for tool mode.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Append .zip to the file name\n",
    "zip_file = f\"{park_name}.zip\"\n",
    "\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(zip_file):\n",
    "    # Create a ZipFile object\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Extract all contents to a folder named after the park code\n",
    "        zip_ref.extractall(f\"{park_name}_unzipped\")\n",
    "        print(f\"Extracted {zip_file} to the folder {park_name}_unzipped\")\n",
    "else:\n",
    "    print(f\"The file {zip_file} does not exist.\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9730fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calendar.txt into a DataFrame.\n",
      "     service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "0        spring       1        1          1         1       1         1   \n",
      "1        summer       1        1          1         1       1         1   \n",
      "2  summerhikers       1        1          1         1       1         1   \n",
      "3          fall       1        1          1         1       1         1   \n",
      "4        winter       1        1          1         1       1         1   \n",
      "\n",
      "   sunday  start_date  end_date  \n",
      "0       1    20240301  20240524  \n",
      "1       1    20240525  20240906  \n",
      "2       1    20240525  20240831  \n",
      "3       1    20240907  20241130  \n",
      "4       1    20231201  20240229  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 3: Import Calendar\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the calendar.txt file\n",
    "calendar_file = os.path.join(unzipped_folder, \"calendar.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(calendar_file):\n",
    "    # Load the calendar.txt into a pandas DataFrame\n",
    "    calendar = pd.read_csv(calendar_file)\n",
    "    print(\"Loaded calendar.txt into a DataFrame.\")\n",
    "    print(calendar.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {calendar_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c5dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active schedules between 2024-08-01 and 2024-09-15:\n",
      "         service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "1            summer       1        1          1         1       1         1   \n",
      "2      summerhikers       1        1          1         1       1         1   \n",
      "3              fall       1        1          1         1       1         1   \n",
      "10        september       1        1          1         1       1         1   \n",
      "14  early september       1        1          1         1       1         1   \n",
      "15    mid september       1        1          1         1       1         1   \n",
      "\n",
      "    sunday start_date   end_date  \n",
      "1        1 2024-05-25 2024-09-06  \n",
      "2        1 2024-05-25 2024-08-31  \n",
      "3        1 2024-09-07 2024-11-30  \n",
      "10       1 2024-09-07 2024-09-30  \n",
      "14       1 2024-09-07 2024-09-09  \n",
      "15       1 2024-09-10 2024-09-19  \n"
     ]
    }
   ],
   "source": [
    "# Convert start_date and end_date columns to datetime \n",
    "calendar['start_date'] = pd.to_datetime(calendar['start_date'], format='%Y%m%d')\n",
    "calendar['end_date'] = pd.to_datetime(calendar['end_date'], format='%Y%m%d')\n",
    "\n",
    "if tool_mode == '1':\n",
    "    if current_date_mode == '2':\n",
    "        # Get the current date as a datetime object\n",
    "        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "        # Filter rows where the current date is between start_date and end_date or end_date is in the future\n",
    "        active_schedules = calendar[(calendar['start_date'] <= current_date) & (calendar['end_date'] >= current_date) | (calendar['end_date'] > current_date)]\n",
    "        print(f\"Active/Future schedules on {current_date.date()}:\")\n",
    "        print(active_schedules)\n",
    "    else:\n",
    "        # Get the current date as a datetime object\n",
    "        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "        # Filter rows where the current date is between start_date and end_date or end_date is in the future\n",
    "        active_schedules = calendar[(calendar['start_date'] <= current_date) & (calendar['end_date'] >= current_date)] \n",
    "        print(f\"Active schedules on {current_date.date()}:\")\n",
    "        print(active_schedules)\n",
    "elif tool_mode == '2':\n",
    "        # Filter rows where the schedule end_date is between custom_start and custom_end\n",
    "        # or the schedule overlaps with the custom date range (starts before custom_end and ends after custom_start)\n",
    "        active_schedules = calendar[(calendar['end_date'] >= custom_start) & (calendar['start_date'] <= custom_end)]\n",
    "        # Display the filtered results\n",
    "        print(f\"Active schedules between {custom_start.date()} and {custom_end.date()}:\")\n",
    "        print(active_schedules)\n",
    "else:\n",
    "        print(\"ERROR\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5de03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trips.txt into a DataFrame.\n",
      "  route_id service_id             trip_id                trip_headsign  \\\n",
      "0  village     spring  village_spring_T01  Grand Canyon Visitor Center   \n",
      "1  village     spring  village_spring_T02  Grand Canyon Visitor Center   \n",
      "2  village     spring  village_spring_T03  Grand Canyon Visitor Center   \n",
      "3  village     spring  village_spring_T04  Grand Canyon Visitor Center   \n",
      "4  village     spring  village_spring_T05  Grand Canyon Visitor Center   \n",
      "\n",
      "   direction_id  block_id shape_id wheelchair_accessible bikes_allowed  \n",
      "0             1       NaN  village                     1             1  \n",
      "1             1       NaN  village                     1             1  \n",
      "2             1       NaN  village                     1             1  \n",
      "3             1       NaN  village                     1             1  \n",
      "4             1       NaN  village                     1             1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 5: Add trips file\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the trips.txt file\n",
    "trips_file = os.path.join(unzipped_folder, \"trips.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(trips_file):\n",
    "    # Load the trips.txt into a pandas DataFrame\n",
    "    trips = pd.read_csv(trips_file)\n",
    "    trips['wheelchair_accessible'] = trips['wheelchair_accessible'].fillna(0)\n",
    "    trips['bikes_allowed'] = trips['bikes_allowed'].fillna(0)\n",
    "    trips['wheelchair_accessible'] = trips['wheelchair_accessible'].apply(lambda x: str(int(x)))\n",
    "    trips['bikes_allowed'] = trips['bikes_allowed'].apply(lambda x: str(int(x)))\n",
    "    trips['wheelchair_accessible'] = trips['wheelchair_accessible'].replace(0, '')\n",
    "    trips['bikes_allowed'] = trips['bikes_allowed'].replace(0, '')\n",
    "    print(\"Loaded trips.txt into a DataFrame.\")\n",
    "    print(trips.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {trips_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d207ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active trips based on active schedules:\n",
      "    route_id     service_id                   trip_id  \\\n",
      "75   village         summer        village_summer_T01   \n",
      "76   village         summer        village_summer_T02   \n",
      "77   village         summer        village_summer_T03   \n",
      "78   village         summer        village_summer_T04   \n",
      "79   village         summer        village_summer_T05   \n",
      "..       ...            ...                       ...   \n",
      "923   hermit  mid september  hermit_mid september_T53   \n",
      "924   hermit  mid september  hermit_mid september_T54   \n",
      "925   hermit  mid september  hermit_mid september_T55   \n",
      "926   hermit  mid september  hermit_mid september_T56   \n",
      "927   hermit  mid september  hermit_mid september_T57   \n",
      "\n",
      "                   trip_headsign  direction_id  block_id shape_id  \\\n",
      "75   Grand Canyon Visitor Center             1       NaN  village   \n",
      "76   Grand Canyon Visitor Center             1       NaN  village   \n",
      "77   Grand Canyon Visitor Center             1       NaN  village   \n",
      "78   Grand Canyon Visitor Center             1       NaN  village   \n",
      "79   Grand Canyon Visitor Center             1       NaN  village   \n",
      "..                           ...           ...       ...      ...   \n",
      "923       Village Route Transfer             1       NaN   hermit   \n",
      "924       Village Route Transfer             1       NaN   hermit   \n",
      "925       Village Route Transfer             1       NaN   hermit   \n",
      "926       Village Route Transfer             1       NaN   hermit   \n",
      "927       Village Route Transfer             1       NaN   hermit   \n",
      "\n",
      "    wheelchair_accessible bikes_allowed  \n",
      "75                      1             1  \n",
      "76                      1             1  \n",
      "77                      1             1  \n",
      "78                      1             1  \n",
      "79                      1             1  \n",
      "..                    ...           ...  \n",
      "923                     0             0  \n",
      "924                     0             0  \n",
      "925                     0             0  \n",
      "926                     0             0  \n",
      "927                     0             0  \n",
      "\n",
      "[517 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Chunk 6: Filter to active trips\n",
    "\n",
    "# Filter trips where service_id in trips matches any service_id in active_schedules\n",
    "active_trips = trips[trips['service_id'].isin(active_schedules['service_id'])]\n",
    "\n",
    "print(\"Active trips based on active schedules:\")\n",
    "print(active_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d027479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stop_times.txt into a DataFrame.\n",
      "              trip_id arrival_time departure_time  stop_id  stop_sequence  \\\n",
      "0  village_spring_T01     07:00:00       07:00:00        1              1   \n",
      "1  village_spring_T01     07:05:00       07:05:00        2              2   \n",
      "2  village_spring_T01     07:08:00       07:08:00        3              3   \n",
      "3  village_spring_T01     07:12:00       07:12:00        4              4   \n",
      "4  village_spring_T01     07:15:00       07:15:00        5              5   \n",
      "\n",
      "                  stop_headsign  pickup_type  drop_off_type  \\\n",
      "0        Market Plaza Westbound          NaN            NaN   \n",
      "1  Shrine of the Ages Westbound          NaN            NaN   \n",
      "2                   Train Depot          NaN            NaN   \n",
      "3            Bright Angel Lodge          NaN            NaN   \n",
      "4         Hermits Rest Transfer          NaN            NaN   \n",
      "\n",
      "   continuous_pickup  continuous_drop_off  shape_dist_traveled  timepoint  \n",
      "0                NaN                  NaN                0.000          1  \n",
      "1                NaN                  NaN                1.367          1  \n",
      "2                NaN                  NaN                1.880          1  \n",
      "3                NaN                  NaN                3.203          1  \n",
      "4                NaN                  NaN                3.569          1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 7: Add stop_times \n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the stop_times.txt file\n",
    "stop_times_file = os.path.join(unzipped_folder, \"stop_times.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(stop_times_file):\n",
    "    # Load the stop_times.txt into a pandas DataFrame\n",
    "    stop_times = pd.read_csv(stop_times_file)\n",
    "    print(\"Loaded stop_times.txt into a DataFrame.\")\n",
    "    print(stop_times.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {stop_times_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1a7460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active stop times DataFrame created with 6200 rows.\n",
      "                 trip_id arrival_time departure_time  stop_id  stop_sequence  \\\n",
      "1125  village_summer_T01     06:30:00       06:30:00        1              1   \n",
      "1126  village_summer_T01     06:36:00       06:36:00        2              2   \n",
      "1127  village_summer_T01     06:38:00       06:38:00        3              3   \n",
      "1128  village_summer_T01     06:42:00       06:42:00        4              4   \n",
      "1129  village_summer_T01     06:44:00       06:44:00        5              5   \n",
      "\n",
      "                     stop_headsign  pickup_type  drop_off_type  \\\n",
      "1125        Market Plaza Westbound          NaN            NaN   \n",
      "1126  Shrine of the Ages Westbound          NaN            NaN   \n",
      "1127                   Train Depot          NaN            NaN   \n",
      "1128            Bright Angel Lodge          NaN            NaN   \n",
      "1129         Hermits Rest Transfer          NaN            NaN   \n",
      "\n",
      "      continuous_pickup  continuous_drop_off  shape_dist_traveled  timepoint  \n",
      "1125                NaN                  NaN                0.000          1  \n",
      "1126                NaN                  NaN                1.367          1  \n",
      "1127                NaN                  NaN                1.880          1  \n",
      "1128                NaN                  NaN                3.203          1  \n",
      "1129                NaN                  NaN                3.569          1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 8: Fitler out active stop times\n",
    "active_stop_times = stop_times[stop_times['trip_id'].isin(active_trips['trip_id'])]\n",
    "\n",
    "print(f\"Active stop times DataFrame created with {len(active_stop_times)} rows.\")\n",
    "print(active_stop_times.head())  # Print the first few rows of the active_stop_times DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17a5d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stops.txt into a DataFrame.\n",
      "   stop_id  stop_code                     stop_name  stop_desc   stop_lat  \\\n",
      "0        1        NaN   Grand Canyon Visitor Center        NaN  36.058240   \n",
      "1        2        NaN        Market Plaza Westbound        NaN  36.054930   \n",
      "2        3        NaN  Shrine of the Ages Westbound        NaN  36.053610   \n",
      "3        4        NaN                   Train Depot        NaN  36.056870   \n",
      "4        5        NaN            Bright Angel Lodge        NaN  36.056388   \n",
      "\n",
      "     stop_lon  zone_id  stop_url  location_type  parent_station  \\\n",
      "0 -112.108430      NaN       NaN            NaN             NaN   \n",
      "1 -112.117860      NaN       NaN            NaN             NaN   \n",
      "2 -112.122500      NaN       NaN            NaN             NaN   \n",
      "3 -112.136330      NaN       NaN            NaN             NaN   \n",
      "4 -112.139996      NaN       NaN            NaN             NaN   \n",
      "\n",
      "   stop_timezone  wheelchair_boarding  \n",
      "0            NaN                    1  \n",
      "1            NaN                    1  \n",
      "2            NaN                    1  \n",
      "3            NaN                    1  \n",
      "4            NaN                    1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 9: Add stops\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the stops.txt file\n",
    "stops_file = os.path.join(unzipped_folder, \"stops.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(stops_file):\n",
    "    # Load the stops.txt into a pandas DataFrame\n",
    "    stops = pd.read_csv(stops_file)\n",
    "    print(\"Loaded stops.txt into a DataFrame.\")\n",
    "    print(stops.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {stops_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51d289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active stop times DataFrame created with 36 rows.\n",
      "   stop_id  stop_code                     stop_name  stop_desc   stop_lat  \\\n",
      "0        1        NaN   Grand Canyon Visitor Center        NaN  36.058240   \n",
      "1        2        NaN        Market Plaza Westbound        NaN  36.054930   \n",
      "2        3        NaN  Shrine of the Ages Westbound        NaN  36.053610   \n",
      "3        4        NaN                   Train Depot        NaN  36.056870   \n",
      "4        5        NaN            Bright Angel Lodge        NaN  36.056388   \n",
      "\n",
      "     stop_lon  zone_id  stop_url  location_type  parent_station  \\\n",
      "0 -112.108430      NaN       NaN            NaN             NaN   \n",
      "1 -112.117860      NaN       NaN            NaN             NaN   \n",
      "2 -112.122500      NaN       NaN            NaN             NaN   \n",
      "3 -112.136330      NaN       NaN            NaN             NaN   \n",
      "4 -112.139996      NaN       NaN            NaN             NaN   \n",
      "\n",
      "   stop_timezone  wheelchair_boarding  \n",
      "0            NaN                    1  \n",
      "1            NaN                    1  \n",
      "2            NaN                    1  \n",
      "3            NaN                    1  \n",
      "4            NaN                    1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 10: Fitler out active stops\n",
    "active_stops = stops[stops['stop_id'].isin(active_stop_times['stop_id'])]\n",
    "\n",
    "print(f\"Active stop times DataFrame created with {len(active_stops)} rows.\")\n",
    "print(active_stops.head())  # Print the first few rows of the active_stop_times DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d934d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes.txt into a DataFrame.\n",
      "  shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  shape_dist_traveled\n",
      "0  village      36.05814    -112.10857                  1                0.000\n",
      "1  village      36.05809    -112.10851                  2                0.008\n",
      "2  village      36.05798    -112.10838                  3                0.025\n",
      "3  village      36.05794    -112.10832                  4                0.032\n",
      "4  village      36.05785    -112.10820                  5                0.046\n"
     ]
    }
   ],
   "source": [
    "# Chunk 11: Add shape files\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the shapes.txt file\n",
    "shape_file = os.path.join(unzipped_folder, \"shapes.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(shape_file):\n",
    "    # Load the shapes.txt into a pandas DataFrame\n",
    "    shapes = pd.read_csv(shape_file)\n",
    "    print(\"Loaded shapes.txt into a DataFrame.\")\n",
    "    print(shapes.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {shape_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f81620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active shapes DataFrame created with 4507 rows.\n",
      "  shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  shape_dist_traveled\n",
      "0  village      36.05814    -112.10857                  1                0.000\n",
      "1  village      36.05809    -112.10851                  2                0.008\n",
      "2  village      36.05798    -112.10838                  3                0.025\n",
      "3  village      36.05794    -112.10832                  4                0.032\n",
      "4  village      36.05785    -112.10820                  5                0.046\n"
     ]
    }
   ],
   "source": [
    "#Chunk 12: Filter to active shapes\n",
    "active_shapes = shapes[shapes['shape_id'].isin(active_trips['shape_id'])]\n",
    "\n",
    "print(f\"Active shapes DataFrame created with {len(active_shapes)} rows.\")\n",
    "print(active_shapes.head())  # Print the first few rows of the active_shapes DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ac60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calendar_dates.txt into a DataFrame.\n",
      "Empty DataFrame\n",
      "Columns: [service_id, date, exception_type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Chunk 13: Add calendar_dates files\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the calendar_dates.txt file\n",
    "cd_file = os.path.join(unzipped_folder, \"calendar_dates.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(cd_file):\n",
    "    # Load the calendar_dates.txt into a pandas DataFrame\n",
    "    cdates = pd.read_csv(cd_file)\n",
    "    print(\"Loaded calendar_dates.txt into a DataFrame.\")\n",
    "    print(cdates.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {shape_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d3e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active calendar dates based on active schedules:\n",
      "Empty DataFrame\n",
      "Columns: [service_id, date, exception_type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Chunk 14: Filter to active calendar dates\n",
    "\n",
    "# Filter trips where service_id in trips matches any service_id in active_schedules\n",
    "active_cdates = cdates[cdates['service_id'].isin(active_schedules['service_id'])]\n",
    "\n",
    "print(\"Active calendar dates based on active schedules:\")\n",
    "print(active_cdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce0fcb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated feed info based on current date and schedule range:\n",
      "  feed_publisher_name                               feed_publisher_url  \\\n",
      "0            NPS GRCA  https://www.nps.gov/subjects/developer/gtfs.htm   \n",
      "\n",
      "  feed_lang feed_start_date feed_end_date feed_version  feed_contact_email  \\\n",
      "0        en        20240525      20241130     20240930  erica.cole@nps.gov   \n",
      "\n",
      "  feed_contact_url  \n",
      "0                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel.Lang\\AppData\\Local\\Temp\\ipykernel_79412\\2955382885.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_schedules['start_date'] = pd.to_datetime(active_schedules['start_date'], errors='coerce', format='%Y%m%d')\n",
      "C:\\Users\\Daniel.Lang\\AppData\\Local\\Temp\\ipykernel_79412\\2955382885.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_schedules['end_date'] = pd.to_datetime(active_schedules['end_date'], errors='coerce', format='%Y%m%d')\n"
     ]
    }
   ],
   "source": [
    "#Chunk 15: Add active feed info\n",
    "active_feed_info = pd.DataFrame({\n",
    "        'feed_publisher_name': [None],\n",
    "        'feed_publisher_url': [None],\n",
    "        'feed_lang': [None],\n",
    "        'feed_start_date': [None],\n",
    "        'feed_end_date': [None],\n",
    "        'feed_version': [None],\n",
    "        'feed_contact_email': [None],\n",
    "        'feed_contact_url': [None]\n",
    "    })\n",
    "    \n",
    "# Find the earliest start_date and latest end_date\n",
    "active_schedules['start_date'] = pd.to_datetime(active_schedules['start_date'], errors='coerce', format='%Y%m%d')\n",
    "active_schedules['end_date'] = pd.to_datetime(active_schedules['end_date'], errors='coerce', format='%Y%m%d')\n",
    "earliest_start_date = active_schedules['start_date'].min().strftime('%Y%m%d')\n",
    "latest_end_date = active_schedules['end_date'].max().strftime('%Y%m%d')\n",
    "\n",
    "# Get the current date in YYYYMMDD format\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Update the active_feed_info DataFrame\n",
    "active_feed_info['feed_start_date'] = earliest_start_date\n",
    "active_feed_info['feed_end_date'] = latest_end_date\n",
    "active_feed_info['feed_version'] = current_date\n",
    "active_feed_info['feed_publisher_name'] = \"NPS \" + park_name\n",
    "active_feed_info['feed_publisher_url'] = \"https://www.nps.gov/subjects/developer/gtfs.htm\"\n",
    "active_feed_info['feed_lang'] = \"en\"\n",
    "active_feed_info['feed_contact_email'] = \"erica.cole@nps.gov\"\n",
    "active_feed_info['feed_contact_url'] = \"\"\n",
    "print(\"Updated feed info based on current date and schedule range:\")\n",
    "print(active_feed_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f84a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dates in active_schedules DataFrame:\n",
      "         service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "1            summer       1        1          1         1       1         1   \n",
      "2      summerhikers       1        1          1         1       1         1   \n",
      "3              fall       1        1          1         1       1         1   \n",
      "10        september       1        1          1         1       1         1   \n",
      "14  early september       1        1          1         1       1         1   \n",
      "\n",
      "    sunday start_date  end_date  \n",
      "1        1   20240525  20240906  \n",
      "2        1   20240525  20240831  \n",
      "3        1   20240907  20241130  \n",
      "10       1   20240907  20240930  \n",
      "14       1   20240907  20240909  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel.Lang\\AppData\\Local\\Temp\\ipykernel_79412\\943231779.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_schedules['start_date'] = active_schedules['start_date'].dt.strftime('%Y%m%d')\n",
      "C:\\Users\\Daniel.Lang\\AppData\\Local\\Temp\\ipykernel_79412\\943231779.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_schedules['end_date'] = active_schedules['end_date'].dt.strftime('%Y%m%d')\n"
     ]
    }
   ],
   "source": [
    "#Chunk 16: Convert calendar dates back to GTFS format (YYYYMMDD)\n",
    "active_schedules['start_date'] = active_schedules['start_date'].dt.strftime('%Y%m%d')\n",
    "active_schedules['end_date'] = active_schedules['end_date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "print(\"Converted dates in active_schedules DataFrame:\")\n",
    "print(active_schedules.head())  # Print the first few rows to verify the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74be4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted all files in GRCA_active_unzipped.\n",
      "All files transferred from GRCA_unzipped to GRCA_active_unzipped.\n"
     ]
    }
   ],
   "source": [
    "#Chunk 17: Create new archive for the active, filtered GTFS feed\n",
    "\n",
    "# Define the source and destination folders \n",
    "source_folder = f\"{park_name}_unzipped\"\n",
    "destination_folder = f\"{park_name}_active_unzipped\"\n",
    "\n",
    "# Check if the destination folder exists\n",
    "if os.path.exists(destination_folder):\n",
    "    # Delete all files in the destination folder\n",
    "    for file_name in os.listdir(destination_folder):\n",
    "        file_path = os.path.join(destination_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(f\"Deleted all files in {destination_folder}.\")\n",
    "else:\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    print(f\"Created destination folder: {destination_folder}.\")\n",
    "\n",
    "# Check if the source folder exists\n",
    "if os.path.exists(source_folder):\n",
    "    # Transfer all files from source to destination\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        # Construct full file path\n",
    "        full_file_name = os.path.join(source_folder, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, destination_folder)\n",
    "    \n",
    "    print(f\"All files transferred from {source_folder} to {destination_folder}.\")\n",
    "else:\n",
    "    print(f\"The source folder {source_folder} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "788bba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted GRCA_active_unzipped\\calendar.txt.\n",
      "Deleted GRCA_active_unzipped\\trips.txt.\n",
      "Deleted GRCA_active_unzipped\\stop_times.txt.\n",
      "Deleted GRCA_active_unzipped\\shapes.txt.\n",
      "Deleted GRCA_active_unzipped\\calendar_dates.txt.\n",
      "Deleted GRCA_active_unzipped\\stops.txt.\n",
      "Deleted GRCA_active_unzipped\\feed_info.txt.\n",
      "Saved active schedules to GRCA_active_unzipped\\calendar.txt.\n",
      "Saved active trips to GRCA_active_unzipped\\trips.txt.\n",
      "Saved active stop times to GRCA_active_unzipped\\stop_times.txt.\n",
      "Saved active shapes to GRCA_active_unzipped\\shapes.txt.\n",
      "Saved active calendar dates to GRCA_active_unzipped\\calendar_dates.txt.\n",
      "Saved active stops to GRCA_active_unzipped\\stops.txt.\n",
      "Saved active feed info dates to GRCA_active_unzipped\\feed_info.txt.\n"
     ]
    }
   ],
   "source": [
    "#Chunk 18: Delete any old files, update to active versions\n",
    "\n",
    "# Define the paths to the files to delete\n",
    "calendar_file_path = os.path.join(destination_folder, \"calendar.txt\")\n",
    "trips_file_path = os.path.join(destination_folder, \"trips.txt\")\n",
    "stop_times_file_path = os.path.join(destination_folder, \"stop_times.txt\")\n",
    "shape_file_path = os.path.join(destination_folder, \"shapes.txt\")\n",
    "cdate_file_path = os.path.join(destination_folder, \"calendar_dates.txt\")\n",
    "stops_file_path = os.path.join(destination_folder, \"stops.txt\")\n",
    "feed_info_file_path = os.path.join(destination_folder, \"feed_info.txt\")\n",
    "\n",
    "# Delete the old files\n",
    "if os.path.exists(calendar_file_path):\n",
    "    os.remove(calendar_file_path)\n",
    "    print(f\"Deleted {calendar_file_path}.\")\n",
    "else:\n",
    "    print(f\"{calendar_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(trips_file_path):\n",
    "    os.remove(trips_file_path)\n",
    "    print(f\"Deleted {trips_file_path}.\")\n",
    "else:\n",
    "    print(f\"{trips_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(stop_times_file_path):\n",
    "    os.remove(stop_times_file_path)\n",
    "    print(f\"Deleted {stop_times_file_path}.\")\n",
    "else:\n",
    "    print(f\"{stop_times_file_path} does not exist.\")\n",
    "    \n",
    "if os.path.exists(shape_file_path):\n",
    "    os.remove(shape_file_path)\n",
    "    print(f\"Deleted {shape_file_path}.\")\n",
    "else:\n",
    "    print(f\"{shape_file_path} does not exist.\")\n",
    "    \n",
    "if os.path.exists(cdate_file_path):\n",
    "    os.remove(cdate_file_path)\n",
    "    print(f\"Deleted {cdate_file_path}.\")\n",
    "else:\n",
    "    print(f\"{cdate_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(stops_file_path):\n",
    "    os.remove(stops_file_path)\n",
    "    print(f\"Deleted {stops_file_path}.\")\n",
    "else:\n",
    "    print(f\"{stops_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(feed_info_file_path):\n",
    "    os.remove(feed_info_file_path)\n",
    "    print(f\"Deleted {feed_info_file_path}.\")\n",
    "else:\n",
    "    print(f\"{feed_info_file_path} does not exist.\")\n",
    "    \n",
    "# Save active info to folder\n",
    "calendar_file = os.path.join(destination_folder, \"calendar.txt\")\n",
    "trips_file = os.path.join(destination_folder, \"trips.txt\")\n",
    "stop_times_file = os.path.join(destination_folder, \"stop_times.txt\")\n",
    "shape_file = os.path.join(destination_folder, \"shapes.txt\")\n",
    "cdate_file = os.path.join(destination_folder, \"calendar_dates.txt\")\n",
    "stops_file = os.path.join(destination_folder, \"stops.txt\")\n",
    "feed_info_file = os.path.join(destination_folder, \"feed_info.txt\")\n",
    "\n",
    "active_schedules.to_csv(calendar_file, sep=',', index=False)\n",
    "active_trips.to_csv(trips_file, sep=',', index=False)\n",
    "active_stop_times.to_csv(stop_times_file, sep=',', index=False)\n",
    "active_shapes.to_csv(shape_file, sep=',', index=False)\n",
    "active_cdates.to_csv(cdate_file, sep=',', index=False)\n",
    "active_stops.to_csv(stops_file, sep=',', index=False)\n",
    "active_feed_info.to_csv(feed_info_file, sep=',', index=False)\n",
    "\n",
    "print(f\"Saved active schedules to {calendar_file}.\")\n",
    "print(f\"Saved active trips to {trips_file}.\")\n",
    "print(f\"Saved active stop times to {stop_times_file}.\")\n",
    "print(f\"Saved active shapes to {shape_file}.\")\n",
    "print(f\"Saved active calendar dates to {cdate_file}.\")\n",
    "print(f\"Saved active stops to {stops_file}.\")\n",
    "print(f\"Saved active feed info dates to {feed_info_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8322b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created zip file: GRCA_active.zip\n"
     ]
    }
   ],
   "source": [
    "#Chunk 19: Zip it all back up\n",
    "\n",
    "# Define the path to the active unzipped folder and the zip file name\n",
    "active_folder = destination_folder\n",
    "zip_file_name = f\"{park_name}_active\"\n",
    "\n",
    "# Create a zip file from the active folder\n",
    "shutil.make_archive(zip_file_name, 'zip', active_folder)\n",
    "\n",
    "print(f\"Created zip file: {zip_file_name}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
