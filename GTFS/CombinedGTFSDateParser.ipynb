{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f79ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunk 1: Import libraries\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165dd571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Park Code: SEKI\n",
      "Do you want the tool to be based on 1. the current date or 2. a custom date range: 1\n",
      "Tool mode entered: 1\n",
      "Show 1. all active schedules or 2. all active and future schedules: 2\n",
      "Current date mode entered: 2\n",
      "Extracted SEKI.zip to the folder SEKI_unzipped\n"
     ]
    }
   ],
   "source": [
    "# Enter Park Code\n",
    "park_name = input(\"Enter the Park Code: \").strip()\n",
    "\n",
    "# Set which calendar to use\n",
    "tool_mode = input(\"Do you want the tool to be based on 1. the current date or 2. a custom date range: \").strip()\n",
    "\n",
    "# Debugging: Check the value of tool_mode\n",
    "print(f\"Tool mode entered: {tool_mode}\")\n",
    "\n",
    "if tool_mode == '1':  # Compare as string\n",
    "    current_date_mode = input(\"Show 1. all active schedules or 2. all active and future schedules: \").strip()\n",
    "    if current_date_mode == '1' or current_date_mode == '2':\n",
    "        print(f\"Current date mode entered: {current_date_mode}\")\n",
    "    else:\n",
    "        print(\"Invalid option selected for tool mode.\")\n",
    "        sys.exit()\n",
    "elif tool_mode == '2':  # Compare as string\n",
    "    custom_start = input(\"Define custom start date as YYYYMMDD: \").strip()\n",
    "    custom_end = input(\"Define custom end date as YYYYMMDD: \").strip()\n",
    "    print(f\"Creating GTFS for dates between {custom_start} and {custom_end}\")\n",
    "    custom_start = pd.to_datetime(custom_start, format='%Y%m%d')\n",
    "    custom_end = pd.to_datetime(custom_end, format='%Y%m%d')\n",
    "else:\n",
    "    print(\"Invalid option selected for tool mode.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Append .zip to the file name\n",
    "zip_file = f\"{park_name}.zip\"\n",
    "\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(zip_file):\n",
    "    # Create a ZipFile object\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Extract all contents to a folder named after the park code\n",
    "        zip_ref.extractall(f\"{park_name}_unzipped\")\n",
    "        print(f\"Extracted {zip_file} to the folder {park_name}_unzipped\")\n",
    "else:\n",
    "    print(f\"The file {zip_file} does not exist.\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9730fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calendar.txt into a DataFrame.\n",
      "        service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "0     12dailyearly       1        1          1         1       1         1   \n",
      "1        12weekday       1        1          1         1       1         0   \n",
      "2      12dailylate       1        1          1         1       1         1   \n",
      "3        12weekend       0        0          0         0       0         1   \n",
      "4  3weekdayOPearly       1        1          1         1       1         0   \n",
      "\n",
      "   sunday  start_date  end_date  \n",
      "0       1    20240523  20240628  \n",
      "1       0    20240701  20240816  \n",
      "2       1    20240819  20240830  \n",
      "3       1    20240629  20240818  \n",
      "4       0    20240523  20240628  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 3: Import Calendar\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the calendar.txt file\n",
    "calendar_file = os.path.join(unzipped_folder, \"calendar.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(calendar_file):\n",
    "    # Load the calendar.txt into a pandas DataFrame\n",
    "    calendar = pd.read_csv(calendar_file)\n",
    "    print(\"Loaded calendar.txt into a DataFrame.\")\n",
    "    print(calendar.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {calendar_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c5dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active/Future schedules on 2024-09-25:\n",
      "       service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "10     winterfull       0        0          0         0       0         0   \n",
      "11  winterpartial       0        0          0         0       0         0   \n",
      "\n",
      "    sunday start_date   end_date  \n",
      "10       0 2024-11-01 2024-12-15  \n",
      "11       0 2024-12-15 2025-03-01  \n"
     ]
    }
   ],
   "source": [
    "# Convert start_date and end_date columns to datetime \n",
    "calendar['start_date'] = pd.to_datetime(calendar['start_date'], format='%Y%m%d')\n",
    "calendar['end_date'] = pd.to_datetime(calendar['end_date'], format='%Y%m%d')\n",
    "\n",
    "if tool_mode == '1':\n",
    "    if current_date_mode == '2':\n",
    "        # Get the current date as a datetime object\n",
    "        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "        # Filter rows where the current date is between start_date and end_date or end_date is in the future\n",
    "        active_schedules = calendar[(calendar['start_date'] <= current_date) & (calendar['end_date'] >= current_date) | (calendar['end_date'] > current_date)]\n",
    "        print(f\"Active/Future schedules on {current_date.date()}:\")\n",
    "        print(active_schedules)\n",
    "    else:\n",
    "        # Get the current date as a datetime object\n",
    "        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "        # Filter rows where the current date is between start_date and end_date or end_date is in the future\n",
    "        active_schedules = calendar[(calendar['start_date'] <= current_date) & (calendar['end_date'] >= current_date)] \n",
    "        print(f\"Active schedules on {current_date.date()}:\")\n",
    "        print(active_schedules)\n",
    "elif tool_mode == '2':\n",
    "        # Filter rows where the schedule end_date is between custom_start and custom_end\n",
    "        # or the schedule overlaps with the custom date range (starts before custom_end and ends after custom_start)\n",
    "        active_schedules = calendar[(calendar['end_date'] >= custom_start) & (calendar['start_date'] <= custom_end)]\n",
    "        # Display the filtered results\n",
    "        print(f\"Active schedules between {custom_start.date()} and {custom_end.date()}:\")\n",
    "        print(active_schedules)\n",
    "else:\n",
    "        print(\"ERROR\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5de03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trips.txt into a DataFrame.\n",
      "  route_id    service_id                       trip_id        trip_headsign  \\\n",
      "0      1ob  12dailyearly  Route1OutboundDailyEarly_T01  Giant Forest Museum   \n",
      "1      1ob  12dailyearly  Route1OutboundDailyEarly_T02  Giant Forest Museum   \n",
      "2      1ob  12dailyearly  Route1OutboundDailyEarly_T03  Giant Forest Museum   \n",
      "3      1ob  12dailyearly  Route1OutboundDailyEarly_T04  Giant Forest Museum   \n",
      "4      1ob  12dailyearly  Route1OutboundDailyEarly_T05  Giant Forest Museum   \n",
      "\n",
      "   direction_id  block_id shape_id wheelchair_accessible bikes_allowed  \n",
      "0             0       NaN      1ob                     0             0  \n",
      "1             0       NaN      1ob                     0             0  \n",
      "2             0       NaN      1ob                     0             0  \n",
      "3             0       NaN      1ob                     0             0  \n",
      "4             0       NaN      1ob                     0             0  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 5: Add trips file\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the trips.txt file\n",
    "trips_file = os.path.join(unzipped_folder, \"trips.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(trips_file):\n",
    "    # Load the trips.txt into a pandas DataFrame\n",
    "    trips = pd.read_csv(trips_file)\n",
    "    trips['wheelchair_accessible'] = trips['wheelchair_accessible'].fillna(0)\n",
    "    trips['bikes_allowed'] = trips['bikes_allowed'].fillna(0)\n",
    "    trips['wheelchair_accessible'] = trips['wheelchair_accessible'].apply(lambda x: str(int(x)))\n",
    "    trips['bikes_allowed'] = trips['bikes_allowed'].apply(lambda x: str(int(x)))\n",
    "    trips['wheelchair_accessible'] = trips['wheelchair_accessible'].replace(0, '')\n",
    "    trips['bikes_allowed'] = trips['bikes_allowed'].replace(0, '')\n",
    "    print(\"Loaded trips.txt into a DataFrame.\")\n",
    "    print(trips.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {trips_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d207ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active trips based on active schedules:\n",
      "             route_id     service_id                   trip_id  \\\n",
      "1227     winterfullob     winterfull    WinterFullOutbound_T01   \n",
      "1228     winterfullob     winterfull    WinterFullOutbound_T02   \n",
      "1229     winterfullob     winterfull    WinterFullOutbound_T03   \n",
      "1230     winterfullob     winterfull    WinterFullOutbound_T04   \n",
      "1231     winterfullob     winterfull    WinterFullOutbound_T05   \n",
      "...               ...            ...                       ...   \n",
      "1330  winterpartialib  winterpartial  WinterPartialInbound_T23   \n",
      "1331  winterpartialib  winterpartial  WinterPartialInbound_T24   \n",
      "1332  winterpartialib  winterpartial  WinterPartialInbound_T25   \n",
      "1333  winterpartialib  winterpartial  WinterPartialInbound_T26   \n",
      "1334  winterpartialib  winterpartial  WinterPartialInbound_T27   \n",
      "\n",
      "                      trip_headsign  direction_id  block_id         shape_id  \\\n",
      "1227  Wuksachi Lodge and Restaurant             0       NaN     winterfullob   \n",
      "1228  Wuksachi Lodge and Restaurant             0       NaN     winterfullob   \n",
      "1229  Wuksachi Lodge and Restaurant             0       NaN     winterfullob   \n",
      "1230  Wuksachi Lodge and Restaurant             0       NaN     winterfullob   \n",
      "1231  Wuksachi Lodge and Restaurant             0       NaN     winterfullob   \n",
      "...                             ...           ...       ...              ...   \n",
      "1330            Giant Forest Museum             1       NaN  winterpartialib   \n",
      "1331            Giant Forest Museum             1       NaN  winterpartialib   \n",
      "1332            Giant Forest Museum             1       NaN  winterpartialib   \n",
      "1333            Giant Forest Museum             1       NaN  winterpartialib   \n",
      "1334            Giant Forest Museum             1       NaN  winterpartialib   \n",
      "\n",
      "     wheelchair_accessible bikes_allowed  \n",
      "1227                     0             0  \n",
      "1228                     0             0  \n",
      "1229                     0             0  \n",
      "1230                     0             0  \n",
      "1231                     0             0  \n",
      "...                    ...           ...  \n",
      "1330                     0             0  \n",
      "1331                     0             0  \n",
      "1332                     0             0  \n",
      "1333                     0             0  \n",
      "1334                     0             0  \n",
      "\n",
      "[108 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Chunk 6: Filter to active trips\n",
    "\n",
    "# Filter trips where service_id in trips matches any service_id in active_schedules\n",
    "active_trips = trips[trips['service_id'].isin(active_schedules['service_id'])]\n",
    "\n",
    "print(\"Active trips based on active schedules:\")\n",
    "print(active_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d027479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stop_times.txt into a DataFrame.\n",
      "                        trip_id arrival_time departure_time  stop_id  \\\n",
      "0  Route1OutboundDailyEarly_T01     08:00:00       08:00:00        8   \n",
      "1  Route1OutboundDailyEarly_T01     08:06:00       08:06:00        7   \n",
      "2  Route1OutboundDailyEarly_T01     08:16:00       08:16:00        4   \n",
      "3  Route1OutboundDailyEarly_T01     08:24:00       08:24:00        3   \n",
      "4  Route1OutboundDailyEarly_T02     08:23:00       08:23:00        8   \n",
      "\n",
      "   stop_sequence  stop_headsign  pickup_type  drop_off_type  \\\n",
      "0              1            NaN          NaN            NaN   \n",
      "1              2            NaN          NaN            NaN   \n",
      "2              3            NaN          NaN            NaN   \n",
      "3              4            NaN          NaN            NaN   \n",
      "4              1            NaN          NaN            NaN   \n",
      "\n",
      "   continuous_pickup  continuous_drop_off  shape_dist_traveled  timepoint  \n",
      "0                NaN                  NaN                0.000          1  \n",
      "1                NaN                  NaN                0.736          1  \n",
      "2                NaN                  NaN                4.464          1  \n",
      "3                NaN                  NaN                8.046          1  \n",
      "4                NaN                  NaN                0.000          1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 7: Add stop_times \n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the stop_times.txt file\n",
    "stop_times_file = os.path.join(unzipped_folder, \"stop_times.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(stop_times_file):\n",
    "    # Load the stop_times.txt into a pandas DataFrame\n",
    "    stop_times = pd.read_csv(stop_times_file)\n",
    "    print(\"Loaded stop_times.txt into a DataFrame.\")\n",
    "    print(stop_times.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {stop_times_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1a7460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active stop times DataFrame created with 432 rows.\n",
      "                     trip_id arrival_time departure_time  stop_id  \\\n",
      "3527  WinterFullOutbound_T01     10:00:00       10:00:00        3   \n",
      "3528  WinterFullOutbound_T01     10:09:00       10:09:00        4   \n",
      "3529  WinterFullOutbound_T01     10:18:00       10:18:00        5   \n",
      "3530  WinterFullOutbound_T01     10:23:00       10:23:00        7   \n",
      "3531  WinterFullOutbound_T01     10:30:00       10:30:00        9   \n",
      "\n",
      "      stop_sequence  stop_headsign  pickup_type  drop_off_type  \\\n",
      "3527              1            NaN          NaN            NaN   \n",
      "3528              2            NaN          NaN            NaN   \n",
      "3529              3            NaN          NaN            NaN   \n",
      "3530              4            NaN          NaN            NaN   \n",
      "3531              5            NaN          NaN            NaN   \n",
      "\n",
      "      continuous_pickup  continuous_drop_off  shape_dist_traveled  timepoint  \n",
      "3527                NaN                  NaN                0.000          1  \n",
      "3528                NaN                  NaN                3.572          1  \n",
      "3529                NaN                  NaN                6.426          1  \n",
      "3530                NaN                  NaN               11.294          1  \n",
      "3531                NaN                  NaN               15.374          1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 7: Fitler out active stop times\n",
    "active_stop_times = stop_times[stop_times['trip_id'].isin(active_trips['trip_id'])]\n",
    "\n",
    "print(f\"Active stop times DataFrame created with {len(active_stop_times)} rows.\")\n",
    "print(active_stop_times.head())  # Print the first few rows of the active_stop_times DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d934d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes.txt into a DataFrame.\n",
      "  shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  shape_dist_traveled\n",
      "0      1ib      36.56433    -118.77326                  1                0.000\n",
      "1      1ib      36.56438    -118.77330                  2                0.007\n",
      "2      1ib      36.56447    -118.77335                  3                0.018\n",
      "3      1ib      36.56459    -118.77348                  4                0.035\n",
      "4      1ib      36.56465    -118.77342                  5                0.044\n"
     ]
    }
   ],
   "source": [
    "# Chunk 9: Add shape files\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the shapes.txt file\n",
    "shape_file = os.path.join(unzipped_folder, \"shapes.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(shape_file):\n",
    "    # Load the shapes.txt into a pandas DataFrame\n",
    "    shapes = pd.read_csv(shape_file)\n",
    "    print(\"Loaded shapes.txt into a DataFrame.\")\n",
    "    print(shapes.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {shape_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f81620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active shapes DataFrame created with 3600 rows.\n",
      "          shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "7138  winterfullob      36.56433    -118.77326                  1   \n",
      "7139  winterfullob      36.56438    -118.77330                  2   \n",
      "7140  winterfullob      36.56447    -118.77335                  3   \n",
      "7141  winterfullob      36.56459    -118.77348                  4   \n",
      "7142  winterfullob      36.56469    -118.77338                  5   \n",
      "\n",
      "      shape_dist_traveled  \n",
      "7138                0.000  \n",
      "7139                0.007  \n",
      "7140                0.018  \n",
      "7141                0.035  \n",
      "7142                0.050  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 10: Filter to active shapes\n",
    "active_shapes = shapes[shapes['shape_id'].isin(active_trips['shape_id'])]\n",
    "\n",
    "print(f\"Active shapes DataFrame created with {len(active_shapes)} rows.\")\n",
    "print(active_shapes.head())  # Print the first few rows of the active_shapes DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ac60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calendar_dates.txt into a DataFrame.\n",
      "     service_id      date  exception_type\n",
      "0  12dailyearly  20240527               2\n",
      "1     12weekend  20240527               1\n",
      "2  12dailyearly  20240619               2\n",
      "3     12weekend  20240619               1\n",
      "4     12weekday  20240704               2\n"
     ]
    }
   ],
   "source": [
    "# Chunk 11: Add calendar_dates files\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the shapes.txt file\n",
    "cd_file = os.path.join(unzipped_folder, \"calendar_dates.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(cd_file):\n",
    "    # Load the calendar_dates.txt into a pandas DataFrame\n",
    "    cdates = pd.read_csv(cd_file)\n",
    "    print(\"Loaded calendar_dates.txt into a DataFrame.\")\n",
    "    print(cdates.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {shape_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d3e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active calendar dates based on active schedules:\n",
      "       service_id      date  exception_type\n",
      "14     winterfull  20241128               1\n",
      "15     winterfull  20241129               1\n",
      "16     winterfull  20241130               1\n",
      "17     winterfull  20241201               1\n",
      "18  winterpartial  20241224               1\n",
      "19  winterpartial  20241225               1\n",
      "20  winterpartial  20241226               1\n",
      "21  winterpartial  20241227               1\n",
      "22  winterpartial  20241228               1\n",
      "23  winterpartial  20241229               1\n",
      "24  winterpartial  20241230               1\n",
      "25  winterpartial  20241231               1\n",
      "26  winterpartial  20250101               1\n",
      "27  winterpartial  20250118               1\n",
      "28  winterpartial  20250119               1\n",
      "29  winterpartial  20250215               1\n",
      "30  winterpartial  20250216               1\n"
     ]
    }
   ],
   "source": [
    "#Chunk 12: Filter to active calendar dates\n",
    "\n",
    "# Filter trips where service_id in trips matches any service_id in active_schedules\n",
    "active_cdates = cdates[cdates['service_id'].isin(active_schedules['service_id'])]\n",
    "\n",
    "print(\"Active calendar dates based on active schedules:\")\n",
    "print(active_cdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f84a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dates in active_schedules DataFrame:\n",
      "       service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "10     winterfull       0        0          0         0       0         0   \n",
      "11  winterpartial       0        0          0         0       0         0   \n",
      "\n",
      "    sunday start_date  end_date  \n",
      "10       0   20241101  20241215  \n",
      "11       0   20241215  20250301  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel.Lang\\AppData\\Local\\Temp\\ipykernel_38524\\1609063719.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_schedules['start_date'] = active_schedules['start_date'].dt.strftime('%Y%m%d')\n",
      "C:\\Users\\Daniel.Lang\\AppData\\Local\\Temp\\ipykernel_38524\\1609063719.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_schedules['end_date'] = active_schedules['end_date'].dt.strftime('%Y%m%d')\n"
     ]
    }
   ],
   "source": [
    "#Chunk 13: Convert calendar dates back to GTFS format (YYYYMMDD)\n",
    "active_schedules['start_date'] = active_schedules['start_date'].dt.strftime('%Y%m%d')\n",
    "active_schedules['end_date'] = active_schedules['end_date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "print(\"Converted dates in active_schedules DataFrame:\")\n",
    "print(active_schedules.head())  # Print the first few rows to verify the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74be4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created destination folder: SEKI_active_unzipped.\n",
      "All files transferred from SEKI_unzipped to SEKI_active_unzipped.\n"
     ]
    }
   ],
   "source": [
    "#Chunk 14: Create new archive for the active, filtered GTFS feed\n",
    "\n",
    "# Define the source and destination folders \n",
    "source_folder = f\"{park_name}_unzipped\"\n",
    "destination_folder = f\"{park_name}_active_unzipped\"\n",
    "\n",
    "# Check if the destination folder exists\n",
    "if os.path.exists(destination_folder):\n",
    "    # Delete all files in the destination folder\n",
    "    for file_name in os.listdir(destination_folder):\n",
    "        file_path = os.path.join(destination_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(f\"Deleted all files in {destination_folder}.\")\n",
    "else:\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    print(f\"Created destination folder: {destination_folder}.\")\n",
    "\n",
    "# Check if the source folder exists\n",
    "if os.path.exists(source_folder):\n",
    "    # Transfer all files from source to destination\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        # Construct full file path\n",
    "        full_file_name = os.path.join(source_folder, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, destination_folder)\n",
    "    \n",
    "    print(f\"All files transferred from {source_folder} to {destination_folder}.\")\n",
    "else:\n",
    "    print(f\"The source folder {source_folder} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788bba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted SEKI_active_unzipped\\calendar.txt.\n",
      "Deleted SEKI_active_unzipped\\trips.txt.\n",
      "Deleted SEKI_active_unzipped\\stop_times.txt.\n",
      "Deleted SEKI_active_unzipped\\shapes.txt.\n",
      "Deleted SEKI_active_unzipped\\calendar_dates.txt.\n",
      "Saved active schedules to SEKI_active_unzipped\\calendar.txt.\n",
      "Saved active trips to SEKI_active_unzipped\\trips.txt.\n",
      "Saved active stop times to SEKI_active_unzipped\\stop_times.txt.\n",
      "Saved active shapes to SEKI_active_unzipped\\shapes.txt.\n",
      "Saved active calendar dates to SEKI_active_unzipped\\calendar_dates.txt.\n"
     ]
    }
   ],
   "source": [
    "#Chunk 15: Delete any old files, update the calendar, text, shapes, and stoptimes to active versions\n",
    "\n",
    "# Define the paths to the files to delete\n",
    "calendar_file_path = os.path.join(destination_folder, \"calendar.txt\")\n",
    "trips_file_path = os.path.join(destination_folder, \"trips.txt\")\n",
    "stop_times_file_path = os.path.join(destination_folder, \"stop_times.txt\")\n",
    "shape_file_path = os.path.join(destination_folder, \"shapes.txt\")\n",
    "cdate_file_path = os.path.join(destination_folder, \"calendar_dates.txt\")\n",
    "\n",
    "# Delete the calendar.txt and trips.txt files\n",
    "if os.path.exists(calendar_file_path):\n",
    "    os.remove(calendar_file_path)\n",
    "    print(f\"Deleted {calendar_file_path}.\")\n",
    "else:\n",
    "    print(f\"{calendar_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(trips_file_path):\n",
    "    os.remove(trips_file_path)\n",
    "    print(f\"Deleted {trips_file_path}.\")\n",
    "else:\n",
    "    print(f\"{trips_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(stop_times_file_path):\n",
    "    os.remove(stop_times_file_path)\n",
    "    print(f\"Deleted {stop_times_file_path}.\")\n",
    "else:\n",
    "    print(f\"{stop_times_file_path} does not exist.\")\n",
    "    \n",
    "if os.path.exists(shape_file_path):\n",
    "    os.remove(shape_file_path)\n",
    "    print(f\"Deleted {shape_file_path}.\")\n",
    "else:\n",
    "    print(f\"{shape_file_path} does not exist.\")\n",
    "    \n",
    "if os.path.exists(cdate_file_path):\n",
    "    os.remove(cdate_file_path)\n",
    "    print(f\"Deleted {cdate_file_path}.\")\n",
    "else:\n",
    "    print(f\"{cdate_file_path} does not exist.\")\n",
    "    \n",
    "# Save active info to folder\n",
    "calendar_file = os.path.join(destination_folder, \"calendar.txt\")\n",
    "trips_file = os.path.join(destination_folder, \"trips.txt\")\n",
    "stop_times_file = os.path.join(destination_folder, \"stop_times.txt\")\n",
    "shape_file = os.path.join(destination_folder, \"shapes.txt\")\n",
    "cdate_file = os.path.join(destination_folder, \"calendar_dates.txt\")\n",
    "\n",
    "active_schedules.to_csv(calendar_file, sep=',', index=False)\n",
    "active_trips.to_csv(trips_file, sep=',', index=False)\n",
    "active_stop_times.to_csv(stop_times_file, sep=',', index=False)\n",
    "active_shapes.to_csv(shape_file, sep=',', index=False)\n",
    "active_cdates.to_csv(cdate_file, sep=',', index=False)\n",
    "\n",
    "print(f\"Saved active schedules to {calendar_file}.\")\n",
    "print(f\"Saved active trips to {trips_file}.\")\n",
    "print(f\"Saved active stop times to {stop_times_file}.\")\n",
    "print(f\"Saved active shapes to {shape_file}.\")\n",
    "print(f\"Saved active calendar dates to {cdate_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8322b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created zip file: SEKI_active.zip\n"
     ]
    }
   ],
   "source": [
    "#Chunk 16: Zip it all back up\n",
    "\n",
    "# Define the path to the active unzipped folder and the zip file name\n",
    "active_folder = destination_folder\n",
    "zip_file_name = f\"{park_name}_active\"\n",
    "\n",
    "# Create a zip file from the active folder\n",
    "shutil.make_archive(zip_file_name, 'zip', active_folder)\n",
    "\n",
    "print(f\"Created zip file: {zip_file_name}.zip\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d19212c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
