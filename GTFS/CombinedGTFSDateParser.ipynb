{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f79ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunk 1: Import libraries\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165dd571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Park Code: BRCA\n",
      "Do you want the tool to be based on 1. the current date or 2. a custom date range: 1\n",
      "Tool mode entered: 1\n",
      "Tool mode entered: 1\n",
      "Show 1. all active schedules or 2. all active and future schedules: 2\n",
      "Current date mode entered: 2\n",
      "Extracted BRCA.zip to the folder BRCA_unzipped\n",
      "Current date mode entered: 2\n",
      "Extracted BRCA.zip to the folder BRCA_unzipped\n"
     ]
    }
   ],
   "source": [
    "#Chunk 2: Initialize\n",
    "# Enter Park Code\n",
    "park_name = input(\"Enter the Park Code: \").strip()\n",
    "\n",
    "# Set which calendar to use\n",
    "tool_mode = input(\"Do you want the tool to be based on 1. the current date or 2. a custom date range: \").strip()\n",
    "\n",
    "# Debugging: Check the value of tool_mode\n",
    "print(f\"Tool mode entered: {tool_mode}\")\n",
    "\n",
    "if tool_mode == '1':  # Compare as string\n",
    "    current_date_mode = input(\"Show 1. all active schedules or 2. all active and future schedules: \").strip()\n",
    "    if current_date_mode == '1' or current_date_mode == '2':\n",
    "        print(f\"Current date mode entered: {current_date_mode}\")\n",
    "    else:\n",
    "        print(\"Invalid option selected for tool mode.\")\n",
    "        sys.exit()\n",
    "elif tool_mode == '2':  # Compare as string\n",
    "    custom_start = input(\"Define custom start date as YYYYMMDD: \").strip()\n",
    "    custom_end = input(\"Define custom end date as YYYYMMDD: \").strip()\n",
    "    print(f\"Creating GTFS for dates between {custom_start} and {custom_end}\")\n",
    "    custom_start = pd.to_datetime(custom_start, format='%Y%m%d')\n",
    "    custom_end = pd.to_datetime(custom_end, format='%Y%m%d')\n",
    "else:\n",
    "    print(\"Invalid option selected for tool mode.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Append .zip to the file name\n",
    "zip_file = f\"{park_name}.zip\"\n",
    "\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(zip_file):\n",
    "    # Create a ZipFile object\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Extract all contents to a folder named after the park code\n",
    "        zip_ref.extractall(f\"{park_name}_unzipped\")\n",
    "        print(f\"Extracted {zip_file} to the folder {park_name}_unzipped\")\n",
    "else:\n",
    "    print(f\"The file {zip_file} does not exist.\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9730fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calendar.txt into a DataFrame.\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0          59       1        1          1         1       1         1       1   \n",
      "\n",
      "   start_date  end_date  \n",
      "0    20240923  20501230  \n",
      "Loaded calendar.txt into a DataFrame.\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0          59       1        1          1         1       1         1       1   \n",
      "\n",
      "   start_date  end_date  \n",
      "0    20240923  20501230  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 3: Import Calendar\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the calendar.txt file\n",
    "calendar_file = os.path.join(unzipped_folder, \"calendar.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(calendar_file):\n",
    "    # Load the calendar.txt into a pandas DataFrame\n",
    "    calendar = pd.read_csv(calendar_file)\n",
    "    print(\"Loaded calendar.txt into a DataFrame.\")\n",
    "    print(calendar.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {calendar_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c5dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active/Future schedules on 2024-10-11:\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0          59       1        1          1         1       1         1       1   \n",
      "\n",
      "  start_date   end_date  \n",
      "0 2024-09-23 2050-12-30  \n",
      "Active/Future schedules on 2024-10-11:\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0          59       1        1          1         1       1         1       1   \n",
      "\n",
      "  start_date   end_date  \n",
      "0 2024-09-23 2050-12-30  \n"
     ]
    }
   ],
   "source": [
    "# Convert start_date and end_date columns to datetime \n",
    "calendar['start_date'] = pd.to_datetime(calendar['start_date'], format='%Y%m%d')\n",
    "calendar['end_date'] = pd.to_datetime(calendar['end_date'], format='%Y%m%d')\n",
    "\n",
    "if tool_mode == '1':\n",
    "    if current_date_mode == '2':\n",
    "        # Get the current date as a datetime object\n",
    "        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "        # Filter rows where the current date is between start_date and end_date or end_date is in the future\n",
    "        active_schedules = calendar[(calendar['start_date'] <= current_date) & (calendar['end_date'] >= current_date) | (calendar['end_date'] > current_date)]\n",
    "        print(f\"Active/Future schedules on {current_date.date()}:\")\n",
    "        print(active_schedules)\n",
    "    else:\n",
    "        # Get the current date as a datetime object\n",
    "        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "        # Filter rows where the current date is between start_date and end_date or end_date is in the future\n",
    "        active_schedules = calendar[(calendar['start_date'] <= current_date) & (calendar['end_date'] >= current_date)] \n",
    "        print(f\"Active schedules on {current_date.date()}:\")\n",
    "        print(active_schedules)\n",
    "elif tool_mode == '2':\n",
    "        # Filter rows where the schedule end_date is between custom_start and custom_end\n",
    "        # or the schedule overlaps with the custom date range (starts before custom_end and ends after custom_start)\n",
    "        active_schedules = calendar[(calendar['end_date'] >= custom_start) & (calendar['start_date'] <= custom_end)]\n",
    "        # Display the filtered results\n",
    "        print(f\"Active schedules between {custom_start.date()} and {custom_end.date()}:\")\n",
    "        print(active_schedules)\n",
    "else:\n",
    "        print(\"ERROR\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5de03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wheelchair Accessible? Yes (1) or No (0): 1\n",
      "Bikes Allowed? Yes (1) or No (0): 1\n",
      "Loaded trips.txt into a DataFrame.\n",
      "   route_id  service_id  trip_id  trip_headsign  trip_short_name  \\\n",
      "0        10          59     2807            NaN              NaN   \n",
      "1        10          59     2808            NaN              NaN   \n",
      "2        10          59     2809            NaN              NaN   \n",
      "3        10          59     2810            NaN              NaN   \n",
      "4        10          59     2811            NaN              NaN   \n",
      "\n",
      "   direction_id block_id  shape_id wheelchair_accessible bikes_allowed  \n",
      "0           NaN  1A-0800        10                     1             1  \n",
      "1           NaN  1A-0900        10                     1             1  \n",
      "2           NaN  1A-1000        10                     1             1  \n",
      "3           NaN  1A-1100        10                     1             1  \n",
      "4           NaN  1A-1200        10                     1             1  \n",
      "Loaded trips.txt into a DataFrame.\n",
      "   route_id  service_id  trip_id  trip_headsign  trip_short_name  \\\n",
      "0        10          59     2807            NaN              NaN   \n",
      "1        10          59     2808            NaN              NaN   \n",
      "2        10          59     2809            NaN              NaN   \n",
      "3        10          59     2810            NaN              NaN   \n",
      "4        10          59     2811            NaN              NaN   \n",
      "\n",
      "   direction_id block_id  shape_id wheelchair_accessible bikes_allowed  \n",
      "0           NaN  1A-0800        10                     1             1  \n",
      "1           NaN  1A-0900        10                     1             1  \n",
      "2           NaN  1A-1000        10                     1             1  \n",
      "3           NaN  1A-1100        10                     1             1  \n",
      "4           NaN  1A-1200        10                     1             1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 5: Add trips file\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the trips.txt file\n",
    "trips_file = os.path.join(unzipped_folder, \"trips.txt\")\n",
    "    \n",
    "if os.path.exists(trips_file): \n",
    "    # Load the trips.txt into a pandas DataFrame\n",
    "    trips = pd.read_csv(trips_file)\n",
    "    \n",
    "    # Check if 'wheelchair_accessible' column exists, if not, create it\n",
    "    if 'wheelchair_accessible' not in trips.columns:\n",
    "        user_input_wheelchair = input(\"Wheelchair Accessible? Yes (1) or No (0): \")\n",
    "        trips['wheelchair_accessible'] = str(int(user_input_wheelchair))  # Assign user input to every row as a string\n",
    "    else:\n",
    "        trips['wheelchair_accessible'] = trips['wheelchair_accessible'].fillna(0)\n",
    "        trips['wheelchair_accessible'] = trips['wheelchair_accessible'].apply(lambda x: str(int(x)))\n",
    "        trips['wheelchair_accessible'] = trips['wheelchair_accessible'].replace(0, '')\n",
    "    \n",
    "    # Check if 'bikes_allowed' column exists, if not, create it\n",
    "    if 'bikes_allowed' not in trips.columns:\n",
    "        user_input_bikes = input(\"Bikes Allowed? Yes (1) or No (0): \")\n",
    "        trips['bikes_allowed'] = str(int(user_input_bikes))  # Assign user input to every row as a string\n",
    "    else:\n",
    "        trips['bikes_allowed'] = trips['bikes_allowed'].fillna(0)\n",
    "        trips['bikes_allowed'] = trips['bikes_allowed'].apply(lambda x: str(int(x)))\n",
    "        trips['bikes_allowed'] = trips['bikes_allowed'].replace(0, '')\n",
    "    \n",
    "    print(\"Loaded trips.txt into a DataFrame.\")\n",
    "    print(trips.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {trips_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d207ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active trips based on active schedules:\n",
      "    route_id  service_id  trip_id  trip_headsign  trip_short_name  \\\n",
      "0         10          59     2807            NaN              NaN   \n",
      "1         10          59     2808            NaN              NaN   \n",
      "2         10          59     2809            NaN              NaN   \n",
      "3         10          59     2810            NaN              NaN   \n",
      "4         10          59     2811            NaN              NaN   \n",
      "5         10          59     2812            NaN              NaN   \n",
      "6         10          59     2813            NaN              NaN   \n",
      "7         10          59     2814            NaN              NaN   \n",
      "8         10          59     2815            NaN              NaN   \n",
      "9         10          59     2816            NaN              NaN   \n",
      "10        10          59     2817            NaN              NaN   \n",
      "11        10          59     2818            NaN              NaN   \n",
      "12        10          59     2819            NaN              NaN   \n",
      "13        10          59     2820            NaN              NaN   \n",
      "14        10          59     2821            NaN              NaN   \n",
      "15        10          59     2822            NaN              NaN   \n",
      "16        10          59     2823            NaN              NaN   \n",
      "17        10          59     2824            NaN              NaN   \n",
      "18        10          59     2825            NaN              NaN   \n",
      "19        10          59     2826            NaN              NaN   \n",
      "20        10          59     2827            NaN              NaN   \n",
      "21        10          59     2828            NaN              NaN   \n",
      "22        10          59     2829            NaN              NaN   \n",
      "23        10          59     2830            NaN              NaN   \n",
      "24        10          59     2831            NaN              NaN   \n",
      "25        10          59     2832            NaN              NaN   \n",
      "26        10          59     2833            NaN              NaN   \n",
      "27        10          59     2834            NaN              NaN   \n",
      "28        10          59     2835            NaN              NaN   \n",
      "29        10          59     2836            NaN              NaN   \n",
      "30        10          59     2837            NaN              NaN   \n",
      "31        10          59     2838            NaN              NaN   \n",
      "32        10          59     2839            NaN              NaN   \n",
      "33        10          59     2840            NaN              NaN   \n",
      "34        10          59     2841            NaN              NaN   \n",
      "35        10          59     2842            NaN              NaN   \n",
      "36        10          59     2843            NaN              NaN   \n",
      "37        10          59     2844            NaN              NaN   \n",
      "38        10          59     2845            NaN              NaN   \n",
      "39        10          59     2846            NaN              NaN   \n",
      "40        10          59     2847            NaN              NaN   \n",
      "41        10          59     2848            NaN              NaN   \n",
      "42        10          59     2849            NaN              NaN   \n",
      "43        10          59     2850            NaN              NaN   \n",
      "44        10          59     2851            NaN              NaN   \n",
      "45        10          59     2852            NaN              NaN   \n",
      "46        10          59     2853            NaN              NaN   \n",
      "47        10          59     2854            NaN              NaN   \n",
      "48        10          59     2855            NaN              NaN   \n",
      "49        10          59     2856            NaN              NaN   \n",
      "50        10          59     2857            NaN              NaN   \n",
      "51        10          59     2858            NaN              NaN   \n",
      "52        10          59     2859            NaN              NaN   \n",
      "53        10          59     2860            NaN              NaN   \n",
      "54        10          59     2861            NaN              NaN   \n",
      "55        10          59     2862            NaN              NaN   \n",
      "\n",
      "    direction_id block_id  shape_id wheelchair_accessible bikes_allowed  \n",
      "0            NaN  1A-0800        10                     1             1  \n",
      "1            NaN  1A-0900        10                     1             1  \n",
      "2            NaN  1A-1000        10                     1             1  \n",
      "3            NaN  1A-1100        10                     1             1  \n",
      "4            NaN  1A-1200        10                     1             1  \n",
      "5            NaN  1P-1300        10                     1             1  \n",
      "6            NaN  1P-1400        10                     1             1  \n",
      "7            NaN  1P-1500        10                     1             1  \n",
      "8            NaN  1P-1600        10                     1             1  \n",
      "9            NaN  1P-1700        10                     1             1  \n",
      "10           NaN  2A-0820        10                     1             1  \n",
      "11           NaN  2A-0924        10                     1             1  \n",
      "12           NaN  2A-1020        10                     1             1  \n",
      "13           NaN  2P-1220        10                     1             1  \n",
      "14           NaN  2P-1320        10                     1             1  \n",
      "15           NaN  2P-1420        10                     1             1  \n",
      "16           NaN  2P-1520        10                     1             1  \n",
      "17           NaN  3A-0840        10                     1             1  \n",
      "18           NaN  3A-0948        10                     1             1  \n",
      "19           NaN  3A-1050        10                     1             1  \n",
      "20           NaN  3A-1150        10                     1             1  \n",
      "21           NaN  3A-1250        10                     1             1  \n",
      "22           NaN  3P-1450        10                     1             1  \n",
      "23           NaN  3P-1550        10                     1             1  \n",
      "24           NaN  4A-0912        10                     1             1  \n",
      "25           NaN  4A-1010        10                     1             1  \n",
      "26           NaN  4A-1110        10                     1             1  \n",
      "27           NaN  4A-1210        10                     1             1  \n",
      "28           NaN  4P-1410        10                     1             1  \n",
      "29           NaN  4P-1510        10                     1             1  \n",
      "30           NaN  4P-1615        10                     1             1  \n",
      "31           NaN  4P-1715        10                     1             1  \n",
      "32           NaN  4P-1310        10                     1             1  \n",
      "33           NaN  5A-0936        10                     1             1  \n",
      "34           NaN  5A-1040        10                     1             1  \n",
      "35           NaN  5A-1140        10                     1             1  \n",
      "36           NaN  5P-1340        10                     1             1  \n",
      "37           NaN  5P-1440        10                     1             1  \n",
      "38           NaN  5P-1540        10                     1             1  \n",
      "39           NaN  5P-1645        10                     1             1  \n",
      "40           NaN  6A-1030        10                     1             1  \n",
      "41           NaN  6A-1130        10                     1             1  \n",
      "42           NaN  6A-1230        10                     1             1  \n",
      "43           NaN  6A-1330        10                     1             1  \n",
      "44           NaN  6A-1430        10                     1             1  \n",
      "45           NaN  6P-1630        10                     1             1  \n",
      "46           NaN  6P-1745        10                     1             1  \n",
      "47           NaN  2D-1120        10                     1             1  \n",
      "48           NaN  5D-1240        10                     1             1  \n",
      "49           NaN  3D-1350        10                     1             1  \n",
      "50           NaN  6D-1530        10                     1             1  \n",
      "51           NaN    PDF 1        10                     1             1  \n",
      "52           NaN    PDF 2        10                     1             1  \n",
      "53           NaN    PDF 3        10                     1             1  \n",
      "54           NaN    PDF 4        10                     1             1  \n",
      "55           NaN    PDF 5        10                     1             1  \n",
      "Active trips based on active schedules:\n",
      "    route_id  service_id  trip_id  trip_headsign  trip_short_name  \\\n",
      "0         10          59     2807            NaN              NaN   \n",
      "1         10          59     2808            NaN              NaN   \n",
      "2         10          59     2809            NaN              NaN   \n",
      "3         10          59     2810            NaN              NaN   \n",
      "4         10          59     2811            NaN              NaN   \n",
      "5         10          59     2812            NaN              NaN   \n",
      "6         10          59     2813            NaN              NaN   \n",
      "7         10          59     2814            NaN              NaN   \n",
      "8         10          59     2815            NaN              NaN   \n",
      "9         10          59     2816            NaN              NaN   \n",
      "10        10          59     2817            NaN              NaN   \n",
      "11        10          59     2818            NaN              NaN   \n",
      "12        10          59     2819            NaN              NaN   \n",
      "13        10          59     2820            NaN              NaN   \n",
      "14        10          59     2821            NaN              NaN   \n",
      "15        10          59     2822            NaN              NaN   \n",
      "16        10          59     2823            NaN              NaN   \n",
      "17        10          59     2824            NaN              NaN   \n",
      "18        10          59     2825            NaN              NaN   \n",
      "19        10          59     2826            NaN              NaN   \n",
      "20        10          59     2827            NaN              NaN   \n",
      "21        10          59     2828            NaN              NaN   \n",
      "22        10          59     2829            NaN              NaN   \n",
      "23        10          59     2830            NaN              NaN   \n",
      "24        10          59     2831            NaN              NaN   \n",
      "25        10          59     2832            NaN              NaN   \n",
      "26        10          59     2833            NaN              NaN   \n",
      "27        10          59     2834            NaN              NaN   \n",
      "28        10          59     2835            NaN              NaN   \n",
      "29        10          59     2836            NaN              NaN   \n",
      "30        10          59     2837            NaN              NaN   \n",
      "31        10          59     2838            NaN              NaN   \n",
      "32        10          59     2839            NaN              NaN   \n",
      "33        10          59     2840            NaN              NaN   \n",
      "34        10          59     2841            NaN              NaN   \n",
      "35        10          59     2842            NaN              NaN   \n",
      "36        10          59     2843            NaN              NaN   \n",
      "37        10          59     2844            NaN              NaN   \n",
      "38        10          59     2845            NaN              NaN   \n",
      "39        10          59     2846            NaN              NaN   \n",
      "40        10          59     2847            NaN              NaN   \n",
      "41        10          59     2848            NaN              NaN   \n",
      "42        10          59     2849            NaN              NaN   \n",
      "43        10          59     2850            NaN              NaN   \n",
      "44        10          59     2851            NaN              NaN   \n",
      "45        10          59     2852            NaN              NaN   \n",
      "46        10          59     2853            NaN              NaN   \n",
      "47        10          59     2854            NaN              NaN   \n",
      "48        10          59     2855            NaN              NaN   \n",
      "49        10          59     2856            NaN              NaN   \n",
      "50        10          59     2857            NaN              NaN   \n",
      "51        10          59     2858            NaN              NaN   \n",
      "52        10          59     2859            NaN              NaN   \n",
      "53        10          59     2860            NaN              NaN   \n",
      "54        10          59     2861            NaN              NaN   \n",
      "55        10          59     2862            NaN              NaN   \n",
      "\n",
      "    direction_id block_id  shape_id wheelchair_accessible bikes_allowed  \n",
      "0            NaN  1A-0800        10                     1             1  \n",
      "1            NaN  1A-0900        10                     1             1  \n",
      "2            NaN  1A-1000        10                     1             1  \n",
      "3            NaN  1A-1100        10                     1             1  \n",
      "4            NaN  1A-1200        10                     1             1  \n",
      "5            NaN  1P-1300        10                     1             1  \n",
      "6            NaN  1P-1400        10                     1             1  \n",
      "7            NaN  1P-1500        10                     1             1  \n",
      "8            NaN  1P-1600        10                     1             1  \n",
      "9            NaN  1P-1700        10                     1             1  \n",
      "10           NaN  2A-0820        10                     1             1  \n",
      "11           NaN  2A-0924        10                     1             1  \n",
      "12           NaN  2A-1020        10                     1             1  \n",
      "13           NaN  2P-1220        10                     1             1  \n",
      "14           NaN  2P-1320        10                     1             1  \n",
      "15           NaN  2P-1420        10                     1             1  \n",
      "16           NaN  2P-1520        10                     1             1  \n",
      "17           NaN  3A-0840        10                     1             1  \n",
      "18           NaN  3A-0948        10                     1             1  \n",
      "19           NaN  3A-1050        10                     1             1  \n",
      "20           NaN  3A-1150        10                     1             1  \n",
      "21           NaN  3A-1250        10                     1             1  \n",
      "22           NaN  3P-1450        10                     1             1  \n",
      "23           NaN  3P-1550        10                     1             1  \n",
      "24           NaN  4A-0912        10                     1             1  \n",
      "25           NaN  4A-1010        10                     1             1  \n",
      "26           NaN  4A-1110        10                     1             1  \n",
      "27           NaN  4A-1210        10                     1             1  \n",
      "28           NaN  4P-1410        10                     1             1  \n",
      "29           NaN  4P-1510        10                     1             1  \n",
      "30           NaN  4P-1615        10                     1             1  \n",
      "31           NaN  4P-1715        10                     1             1  \n",
      "32           NaN  4P-1310        10                     1             1  \n",
      "33           NaN  5A-0936        10                     1             1  \n",
      "34           NaN  5A-1040        10                     1             1  \n",
      "35           NaN  5A-1140        10                     1             1  \n",
      "36           NaN  5P-1340        10                     1             1  \n",
      "37           NaN  5P-1440        10                     1             1  \n",
      "38           NaN  5P-1540        10                     1             1  \n",
      "39           NaN  5P-1645        10                     1             1  \n",
      "40           NaN  6A-1030        10                     1             1  \n",
      "41           NaN  6A-1130        10                     1             1  \n",
      "42           NaN  6A-1230        10                     1             1  \n",
      "43           NaN  6A-1330        10                     1             1  \n",
      "44           NaN  6A-1430        10                     1             1  \n",
      "45           NaN  6P-1630        10                     1             1  \n",
      "46           NaN  6P-1745        10                     1             1  \n",
      "47           NaN  2D-1120        10                     1             1  \n",
      "48           NaN  5D-1240        10                     1             1  \n",
      "49           NaN  3D-1350        10                     1             1  \n",
      "50           NaN  6D-1530        10                     1             1  \n",
      "51           NaN    PDF 1        10                     1             1  \n",
      "52           NaN    PDF 2        10                     1             1  \n",
      "53           NaN    PDF 3        10                     1             1  \n",
      "54           NaN    PDF 4        10                     1             1  \n",
      "55           NaN    PDF 5        10                     1             1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 6: Filter to active trips\n",
    "\n",
    "# Filter trips where service_id in trips matches any service_id in active_schedules\n",
    "active_trips = trips[trips['service_id'].isin(active_schedules['service_id'])]\n",
    "\n",
    "print(\"Active trips based on active schedules:\")\n",
    "print(active_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d027479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stop_times.txt into a DataFrame.\n",
      "   trip_id arrival_time departure_time  stop_id  stop_sequence  stop_headsign  \\\n",
      "0     2807     08:00:00       08:00:00        1              1            NaN   \n",
      "1     2807     08:02:00       08:02:00       12              2            NaN   \n",
      "2     2807     08:03:00       08:03:00       13              3            NaN   \n",
      "3     2807     08:04:00       08:04:00       14              4            NaN   \n",
      "4     2807     08:06:00       08:06:00       15              5            NaN   \n",
      "\n",
      "   pickup_type  drop_off_type  timepoint  \n",
      "0            0              0          1  \n",
      "1            0              0          1  \n",
      "2            0              0          1  \n",
      "3            0              0          1  \n",
      "4            0              0          1  \n",
      "Loaded stop_times.txt into a DataFrame.\n",
      "   trip_id arrival_time departure_time  stop_id  stop_sequence  stop_headsign  \\\n",
      "0     2807     08:00:00       08:00:00        1              1            NaN   \n",
      "1     2807     08:02:00       08:02:00       12              2            NaN   \n",
      "2     2807     08:03:00       08:03:00       13              3            NaN   \n",
      "3     2807     08:04:00       08:04:00       14              4            NaN   \n",
      "4     2807     08:06:00       08:06:00       15              5            NaN   \n",
      "\n",
      "   pickup_type  drop_off_type  timepoint  \n",
      "0            0              0          1  \n",
      "1            0              0          1  \n",
      "2            0              0          1  \n",
      "3            0              0          1  \n",
      "4            0              0          1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 7: Add stop_times \n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the stop_times.txt file\n",
    "stop_times_file = os.path.join(unzipped_folder, \"stop_times.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(stop_times_file):\n",
    "    # Load the stop_times.txt into a pandas DataFrame\n",
    "    stop_times = pd.read_csv(stop_times_file)\n",
    "    print(\"Loaded stop_times.txt into a DataFrame.\")\n",
    "    print(stop_times.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {stop_times_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1a7460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active stop times DataFrame created with 896 rows.\n",
      "   trip_id arrival_time departure_time  stop_id  stop_sequence  stop_headsign  \\\n",
      "0     2807     08:00:00       08:00:00        1              1            NaN   \n",
      "1     2807     08:02:00       08:02:00       12              2            NaN   \n",
      "2     2807     08:03:00       08:03:00       13              3            NaN   \n",
      "3     2807     08:04:00       08:04:00       14              4            NaN   \n",
      "4     2807     08:06:00       08:06:00       15              5            NaN   \n",
      "\n",
      "   pickup_type  drop_off_type  timepoint  \n",
      "0            0              0          1  \n",
      "1            0              0          1  \n",
      "2            0              0          1  \n",
      "3            0              0          1  \n",
      "4            0              0          1  \n",
      "Active stop times DataFrame created with 896 rows.\n",
      "   trip_id arrival_time departure_time  stop_id  stop_sequence  stop_headsign  \\\n",
      "0     2807     08:00:00       08:00:00        1              1            NaN   \n",
      "1     2807     08:02:00       08:02:00       12              2            NaN   \n",
      "2     2807     08:03:00       08:03:00       13              3            NaN   \n",
      "3     2807     08:04:00       08:04:00       14              4            NaN   \n",
      "4     2807     08:06:00       08:06:00       15              5            NaN   \n",
      "\n",
      "   pickup_type  drop_off_type  timepoint  \n",
      "0            0              0          1  \n",
      "1            0              0          1  \n",
      "2            0              0          1  \n",
      "3            0              0          1  \n",
      "4            0              0          1  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 8: Fitler out active stop times\n",
    "active_stop_times = stop_times[stop_times['trip_id'].isin(active_trips['trip_id'])]\n",
    "\n",
    "print(f\"Active stop times DataFrame created with {len(active_stop_times)} rows.\")\n",
    "print(active_stop_times.head())  # Print the first few rows of the active_stop_times DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17a5d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stops.txt into a DataFrame.\n",
      "   stop_id  stop_code                 stop_name  stop_desc   stop_lat  \\\n",
      "0        1        NaN           Shuttle Station        NaN  37.671111   \n",
      "1       12        NaN            Old Bryce Town        NaN  37.673567   \n",
      "2       13        NaN  Bryce Canyon Grand Hotel        NaN  37.674484   \n",
      "3       14        NaN                Ruby's Inn        NaN  37.673443   \n",
      "4       15        NaN    Ruby's Campground (SB)        NaN  37.667808   \n",
      "\n",
      "     stop_lon  stop_url  location_type  parent_station  \n",
      "0 -112.156920       NaN              0             NaN  \n",
      "1 -112.156457       NaN              0             NaN  \n",
      "2 -112.154010       NaN              0             NaN  \n",
      "3 -112.156700       NaN              0             NaN  \n",
      "4 -112.158195       NaN              0             NaN  \n",
      "Loaded stops.txt into a DataFrame.\n",
      "   stop_id  stop_code                 stop_name  stop_desc   stop_lat  \\\n",
      "0        1        NaN           Shuttle Station        NaN  37.671111   \n",
      "1       12        NaN            Old Bryce Town        NaN  37.673567   \n",
      "2       13        NaN  Bryce Canyon Grand Hotel        NaN  37.674484   \n",
      "3       14        NaN                Ruby's Inn        NaN  37.673443   \n",
      "4       15        NaN    Ruby's Campground (SB)        NaN  37.667808   \n",
      "\n",
      "     stop_lon  stop_url  location_type  parent_station  \n",
      "0 -112.156920       NaN              0             NaN  \n",
      "1 -112.156457       NaN              0             NaN  \n",
      "2 -112.154010       NaN              0             NaN  \n",
      "3 -112.156700       NaN              0             NaN  \n",
      "4 -112.158195       NaN              0             NaN  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 9: Add stops\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the stops.txt file\n",
    "stops_file = os.path.join(unzipped_folder, \"stops.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(stops_file):\n",
    "    # Load the stops.txt into a pandas DataFrame\n",
    "    stops = pd.read_csv(stops_file)\n",
    "    print(\"Loaded stops.txt into a DataFrame.\")\n",
    "    print(stops.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {stops_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51d289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active stop times DataFrame created with 16 rows.\n",
      "   stop_id  stop_code                 stop_name  stop_desc   stop_lat  \\\n",
      "0        1        NaN           Shuttle Station        NaN  37.671111   \n",
      "1       12        NaN            Old Bryce Town        NaN  37.673567   \n",
      "2       13        NaN  Bryce Canyon Grand Hotel        NaN  37.674484   \n",
      "3       14        NaN                Ruby's Inn        NaN  37.673443   \n",
      "4       15        NaN    Ruby's Campground (SB)        NaN  37.667808   \n",
      "\n",
      "     stop_lon  stop_url  location_type  parent_station  \n",
      "0 -112.156920       NaN              0             NaN  \n",
      "1 -112.156457       NaN              0             NaN  \n",
      "2 -112.154010       NaN              0             NaN  \n",
      "3 -112.156700       NaN              0             NaN  \n",
      "4 -112.158195       NaN              0             NaN  \n",
      "Active stop times DataFrame created with 16 rows.\n",
      "   stop_id  stop_code                 stop_name  stop_desc   stop_lat  \\\n",
      "0        1        NaN           Shuttle Station        NaN  37.671111   \n",
      "1       12        NaN            Old Bryce Town        NaN  37.673567   \n",
      "2       13        NaN  Bryce Canyon Grand Hotel        NaN  37.674484   \n",
      "3       14        NaN                Ruby's Inn        NaN  37.673443   \n",
      "4       15        NaN    Ruby's Campground (SB)        NaN  37.667808   \n",
      "\n",
      "     stop_lon  stop_url  location_type  parent_station  \n",
      "0 -112.156920       NaN              0             NaN  \n",
      "1 -112.156457       NaN              0             NaN  \n",
      "2 -112.154010       NaN              0             NaN  \n",
      "3 -112.156700       NaN              0             NaN  \n",
      "4 -112.158195       NaN              0             NaN  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 10: Fitler out active stops\n",
    "active_stops = stops[stops['stop_id'].isin(active_stop_times['stop_id'])]\n",
    "\n",
    "print(f\"Active stop times DataFrame created with {len(active_stops)} rows.\")\n",
    "print(active_stops.head())  # Print the first few rows of the active_stop_times DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d934d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes.txt into a DataFrame.\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0        10     37.671110   -112.156930                  1   \n",
      "1        10     37.671229   -112.156891                  2   \n",
      "2        10     37.671270   -112.157130                  3   \n",
      "3        10     37.672390   -112.156860                  4   \n",
      "4        10     37.672510   -112.156830                  5   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n",
      "Loaded shapes.txt into a DataFrame.\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0        10     37.671110   -112.156930                  1   \n",
      "1        10     37.671229   -112.156891                  2   \n",
      "2        10     37.671270   -112.157130                  3   \n",
      "3        10     37.672390   -112.156860                  4   \n",
      "4        10     37.672510   -112.156830                  5   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# Chunk 11: Add shape files\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the shapes.txt file\n",
    "shape_file = os.path.join(unzipped_folder, \"shapes.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(shape_file):\n",
    "    # Load the shapes.txt into a pandas DataFrame\n",
    "    shapes = pd.read_csv(shape_file)\n",
    "    print(\"Loaded shapes.txt into a DataFrame.\")\n",
    "    print(shapes.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {shape_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f81620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active shapes DataFrame created with 1159 rows.\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0        10     37.671110   -112.156930                  1   \n",
      "1        10     37.671229   -112.156891                  2   \n",
      "2        10     37.671270   -112.157130                  3   \n",
      "3        10     37.672390   -112.156860                  4   \n",
      "4        10     37.672510   -112.156830                  5   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n",
      "Active shapes DataFrame created with 1159 rows.\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0        10     37.671110   -112.156930                  1   \n",
      "1        10     37.671229   -112.156891                  2   \n",
      "2        10     37.671270   -112.157130                  3   \n",
      "3        10     37.672390   -112.156860                  4   \n",
      "4        10     37.672510   -112.156830                  5   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 12: Filter to active shapes\n",
    "active_shapes = shapes[shapes['shape_id'].isin(active_trips['shape_id'])]\n",
    "\n",
    "print(f\"Active shapes DataFrame created with {len(active_shapes)} rows.\")\n",
    "print(active_shapes.head())  # Print the first few rows of the active_shapes DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ac60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calendar_dates.txt into a DataFrame.\n",
      "Empty DataFrame\n",
      "Columns: [service_id, date, exception_type]\n",
      "Index: []\n",
      "Loaded calendar_dates.txt into a DataFrame.\n",
      "Empty DataFrame\n",
      "Columns: [service_id, date, exception_type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Chunk 13: Add calendar_dates files\n",
    "\n",
    "# Define the path to the unzipped folder\n",
    "unzipped_folder = f\"{park_name}_unzipped\"\n",
    "\n",
    "# Define the path to the calendar_dates.txt file\n",
    "cd_file = os.path.join(unzipped_folder, \"calendar_dates.txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(cd_file):\n",
    "    # Load the calendar_dates.txt into a pandas DataFrame\n",
    "    cdates = pd.read_csv(cd_file)\n",
    "    print(\"Loaded calendar_dates.txt into a DataFrame.\")\n",
    "    print(cdates.head())  # Print the first few rows of the DataFrame\n",
    "else:\n",
    "    print(f\"The file {shape_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d3e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active calendar dates based on active schedules:\n",
      "Empty DataFrame\n",
      "Columns: [service_id, date, exception_type]\n",
      "Index: []\n",
      "Active calendar dates based on active schedules:\n",
      "Empty DataFrame\n",
      "Columns: [service_id, date, exception_type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Chunk 14: Filter to active calendar dates\n",
    "\n",
    "# Filter trips where service_id in trips matches any service_id in active_schedules\n",
    "active_cdates = cdates[cdates['service_id'].isin(active_schedules['service_id'])]\n",
    "\n",
    "print(\"Active calendar dates based on active schedules:\")\n",
    "print(active_cdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce0fcb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated feed info based on current date and schedule range:\n",
      "  feed_publisher_name                               feed_publisher_url  \\\n",
      "0            NPS BRCA  https://www.nps.gov/subjects/developer/gtfs.htm   \n",
      "\n",
      "  feed_lang feed_start_date feed_end_date feed_version  feed_contact_email  \\\n",
      "0        en        20240923      20501230     20241011  erica.cole@nps.gov   \n",
      "\n",
      "  feed_contact_url  \n",
      "0                   \n",
      "Updated feed info based on current date and schedule range:\n",
      "  feed_publisher_name                               feed_publisher_url  \\\n",
      "0            NPS BRCA  https://www.nps.gov/subjects/developer/gtfs.htm   \n",
      "\n",
      "  feed_lang feed_start_date feed_end_date feed_version  feed_contact_email  \\\n",
      "0        en        20240923      20501230     20241011  erica.cole@nps.gov   \n",
      "\n",
      "  feed_contact_url  \n",
      "0                   \n"
     ]
    }
   ],
   "source": [
    "#Chunk 15: Add active feed info\n",
    "active_feed_info = pd.DataFrame({\n",
    "        'feed_publisher_name': [None],\n",
    "        'feed_publisher_url': [None],\n",
    "        'feed_lang': [None],\n",
    "        'feed_start_date': [None],\n",
    "        'feed_end_date': [None],\n",
    "        'feed_version': [None],\n",
    "        'feed_contact_email': [None],\n",
    "        'feed_contact_url': [None]\n",
    "    })\n",
    "    \n",
    "# Find the earliest start_date and latest end_date\n",
    "active_schedules['start_date'] = pd.to_datetime(active_schedules['start_date'], errors='coerce', format='%Y%m%d')\n",
    "active_schedules['end_date'] = pd.to_datetime(active_schedules['end_date'], errors='coerce', format='%Y%m%d')\n",
    "earliest_start_date = active_schedules['start_date'].min().strftime('%Y%m%d')\n",
    "latest_end_date = active_schedules['end_date'].max().strftime('%Y%m%d')\n",
    "\n",
    "# Get the current date in YYYYMMDD format\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Update the active_feed_info DataFrame\n",
    "active_feed_info['feed_start_date'] = earliest_start_date\n",
    "active_feed_info['feed_end_date'] = latest_end_date\n",
    "active_feed_info['feed_version'] = current_date\n",
    "active_feed_info['feed_publisher_name'] = \"NPS \" + park_name\n",
    "active_feed_info['feed_publisher_url'] = \"https://www.nps.gov/subjects/developer/gtfs.htm\"\n",
    "active_feed_info['feed_lang'] = \"en\"\n",
    "active_feed_info['feed_contact_email'] = \"erica.cole@nps.gov\"\n",
    "active_feed_info['feed_contact_url'] = \"\"\n",
    "print(\"Updated feed info based on current date and schedule range:\")\n",
    "print(active_feed_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f84a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dates in active_schedules DataFrame:\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0          59       1        1          1         1       1         1       1   \n",
      "\n",
      "  start_date  end_date  \n",
      "0   20240923  20501230  \n",
      "Converted dates in active_schedules DataFrame:\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0          59       1        1          1         1       1         1       1   \n",
      "\n",
      "  start_date  end_date  \n",
      "0   20240923  20501230  \n"
     ]
    }
   ],
   "source": [
    "#Chunk 16: Convert calendar dates back to GTFS format (YYYYMMDD)\n",
    "active_schedules['start_date'] = active_schedules['start_date'].dt.strftime('%Y%m%d')\n",
    "active_schedules['end_date'] = active_schedules['end_date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "print(\"Converted dates in active_schedules DataFrame:\")\n",
    "print(active_schedules.head())  # Print the first few rows to verify the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74be4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted all files in BRCA_active_unzipped.\n",
      "Deleted all files in BRCA_active_unzipped.\n",
      "All files transferred from BRCA_unzipped to BRCA_active_unzipped.\n",
      "All files transferred from BRCA_unzipped to BRCA_active_unzipped.\n"
     ]
    }
   ],
   "source": [
    "#Chunk 17: Create new archive for the active, filtered GTFS feed\n",
    "\n",
    "# Define the source and destination folders \n",
    "source_folder = f\"{park_name}_unzipped\"\n",
    "destination_folder = f\"{park_name}_active_unzipped\"\n",
    "\n",
    "# Check if the destination folder exists\n",
    "if os.path.exists(destination_folder):\n",
    "    # Delete all files in the destination folder\n",
    "    for file_name in os.listdir(destination_folder):\n",
    "        file_path = os.path.join(destination_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(f\"Deleted all files in {destination_folder}.\")\n",
    "else:\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    print(f\"Created destination folder: {destination_folder}.\")\n",
    "\n",
    "# Check if the source folder exists\n",
    "if os.path.exists(source_folder):\n",
    "    # Transfer all files from source to destination\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        # Construct full file path\n",
    "        full_file_name = os.path.join(source_folder, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, destination_folder)\n",
    "    \n",
    "    print(f\"All files transferred from {source_folder} to {destination_folder}.\")\n",
    "else:\n",
    "    print(f\"The source folder {source_folder} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "788bba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted BRCA_active_unzipped\\calendar.txt.\n",
      "Deleted BRCA_active_unzipped\\calendar.txt.\n",
      "Deleted BRCA_active_unzipped\\trips.txt.\n",
      "Deleted BRCA_active_unzipped\\stop_times.txt.\n",
      "Deleted BRCA_active_unzipped\\shapes.txt.\n",
      "Deleted BRCA_active_unzipped\\calendar_dates.txt.\n",
      "Deleted BRCA_active_unzipped\\stops.txt.\n",
      "Deleted BRCA_active_unzipped\\feed_info.txt.\n",
      "Deleted BRCA_active_unzipped\\trips.txt.\n",
      "Deleted BRCA_active_unzipped\\stop_times.txt.\n",
      "Deleted BRCA_active_unzipped\\shapes.txt.\n",
      "Deleted BRCA_active_unzipped\\calendar_dates.txt.\n",
      "Deleted BRCA_active_unzipped\\stops.txt.\n",
      "Deleted BRCA_active_unzipped\\feed_info.txt.\n",
      "Saved active schedules to BRCA_active_unzipped\\calendar.txt.\n",
      "Saved active trips to BRCA_active_unzipped\\trips.txt.\n",
      "Saved active stop times to BRCA_active_unzipped\\stop_times.txt.\n",
      "Saved active shapes to BRCA_active_unzipped\\shapes.txt.\n",
      "Saved active calendar dates to BRCA_active_unzipped\\calendar_dates.txt.\n",
      "Saved active stops to BRCA_active_unzipped\\stops.txt.\n",
      "Saved active feed info dates to BRCA_active_unzipped\\feed_info.txt.\n",
      "Saved active schedules to BRCA_active_unzipped\\calendar.txt.\n",
      "Saved active trips to BRCA_active_unzipped\\trips.txt.\n",
      "Saved active stop times to BRCA_active_unzipped\\stop_times.txt.\n",
      "Saved active shapes to BRCA_active_unzipped\\shapes.txt.\n",
      "Saved active calendar dates to BRCA_active_unzipped\\calendar_dates.txt.\n",
      "Saved active stops to BRCA_active_unzipped\\stops.txt.\n",
      "Saved active feed info dates to BRCA_active_unzipped\\feed_info.txt.\n"
     ]
    }
   ],
   "source": [
    "#Chunk 18: Delete any old files, update to active versions\n",
    "\n",
    "# Define the paths to the files to delete\n",
    "calendar_file_path = os.path.join(destination_folder, \"calendar.txt\")\n",
    "trips_file_path = os.path.join(destination_folder, \"trips.txt\")\n",
    "stop_times_file_path = os.path.join(destination_folder, \"stop_times.txt\")\n",
    "shape_file_path = os.path.join(destination_folder, \"shapes.txt\")\n",
    "cdate_file_path = os.path.join(destination_folder, \"calendar_dates.txt\")\n",
    "stops_file_path = os.path.join(destination_folder, \"stops.txt\")\n",
    "feed_info_file_path = os.path.join(destination_folder, \"feed_info.txt\")\n",
    "\n",
    "# Delete the old files\n",
    "if os.path.exists(calendar_file_path):\n",
    "    os.remove(calendar_file_path)\n",
    "    print(f\"Deleted {calendar_file_path}.\")\n",
    "else:\n",
    "    print(f\"{calendar_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(trips_file_path):\n",
    "    os.remove(trips_file_path)\n",
    "    print(f\"Deleted {trips_file_path}.\")\n",
    "else:\n",
    "    print(f\"{trips_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(stop_times_file_path):\n",
    "    os.remove(stop_times_file_path)\n",
    "    print(f\"Deleted {stop_times_file_path}.\")\n",
    "else:\n",
    "    print(f\"{stop_times_file_path} does not exist.\")\n",
    "    \n",
    "if os.path.exists(shape_file_path):\n",
    "    os.remove(shape_file_path)\n",
    "    print(f\"Deleted {shape_file_path}.\")\n",
    "else:\n",
    "    print(f\"{shape_file_path} does not exist.\")\n",
    "    \n",
    "if os.path.exists(cdate_file_path):\n",
    "    os.remove(cdate_file_path)\n",
    "    print(f\"Deleted {cdate_file_path}.\")\n",
    "else:\n",
    "    print(f\"{cdate_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(stops_file_path):\n",
    "    os.remove(stops_file_path)\n",
    "    print(f\"Deleted {stops_file_path}.\")\n",
    "else:\n",
    "    print(f\"{stops_file_path} does not exist.\")\n",
    "\n",
    "if os.path.exists(feed_info_file_path):\n",
    "    os.remove(feed_info_file_path)\n",
    "    print(f\"Deleted {feed_info_file_path}.\")\n",
    "else:\n",
    "    print(f\"{feed_info_file_path} does not exist.\")\n",
    "    \n",
    "# Save active info to folder\n",
    "calendar_file = os.path.join(destination_folder, \"calendar.txt\")\n",
    "trips_file = os.path.join(destination_folder, \"trips.txt\")\n",
    "stop_times_file = os.path.join(destination_folder, \"stop_times.txt\")\n",
    "shape_file = os.path.join(destination_folder, \"shapes.txt\")\n",
    "cdate_file = os.path.join(destination_folder, \"calendar_dates.txt\")\n",
    "stops_file = os.path.join(destination_folder, \"stops.txt\")\n",
    "feed_info_file = os.path.join(destination_folder, \"feed_info.txt\")\n",
    "\n",
    "active_schedules.to_csv(calendar_file, sep=',', index=False)\n",
    "active_trips.to_csv(trips_file, sep=',', index=False)\n",
    "active_stop_times.to_csv(stop_times_file, sep=',', index=False)\n",
    "active_shapes.to_csv(shape_file, sep=',', index=False)\n",
    "active_cdates.to_csv(cdate_file, sep=',', index=False)\n",
    "active_stops.to_csv(stops_file, sep=',', index=False)\n",
    "active_feed_info.to_csv(feed_info_file, sep=',', index=False)\n",
    "\n",
    "print(f\"Saved active schedules to {calendar_file}.\")\n",
    "print(f\"Saved active trips to {trips_file}.\")\n",
    "print(f\"Saved active stop times to {stop_times_file}.\")\n",
    "print(f\"Saved active shapes to {shape_file}.\")\n",
    "print(f\"Saved active calendar dates to {cdate_file}.\")\n",
    "print(f\"Saved active stops to {stops_file}.\")\n",
    "print(f\"Saved active feed info dates to {feed_info_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8322b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created zip file: BRCA_active.zip\n",
      "Created zip file: BRCA_active.zip\n"
     ]
    }
   ],
   "source": [
    "#Chunk 19: Zip it all back up\n",
    "\n",
    "# Define the path to the active unzipped folder and the zip file name\n",
    "active_folder = destination_folder\n",
    "zip_file_name = f\"{park_name}_active\"\n",
    "\n",
    "# Create a zip file from the active folder\n",
    "shutil.make_archive(zip_file_name, 'zip', active_folder)\n",
    "\n",
    "print(f\"Created zip file: {zip_file_name}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
